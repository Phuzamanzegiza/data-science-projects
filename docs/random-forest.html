<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Francis Ngema" />

<meta name="date" content="2024-06-07" />

<title>Consumer Behaviour of Certified ice Customers</title>

<script src="site_libs/header-attrs-2.26/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<!-- header.html -->
<style>
body {
  font-family: 'Montserrat', sans-serif;
}

h1, h2, h3, h4, h5, h6 {
  color: #333;
}

p {
  color: #555;
}

.container-fluid {
  margin-top: 10px; /* Adjust based on the navbar height */
}
</style>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #204a87; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #204a87; font-weight: bold; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Projects</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="hierarchical-clustering.html">Hierarchical Clustering</a>
</li>
<li>
  <a href="random-forest.html">Consumer Behaviour</a>
</li>
<li>
  <a href="pca-kmeans-clustering.html">Customer Segmentation</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <link rel="stylesheet" href="styles.css">
  <style>
    body {
      font-family: 'Montserrat', sans-serif;
    }

    .navbar {
      background-color: #2c3e50;
      border: none;
    }

    .navbar-header .navbar-brand {
      font-weight: bold;
      font-size: 24px;
      color: #ecf0f1 !important;
    }

    .navbar-nav > li > a {
      color: #ecf0f1 !important;
      padding: 15px 20px;
      transition: background-color 0.3s ease;
    }

    .navbar-nav > li > a:hover, 
    .navbar-nav > li > a:focus {
      background-color: #34495e;
      color: #ecf0f1 !important;
    }

    .navbar-toggle {
      border-color: transparent;
    }

    .navbar-toggle .icon-bar {
      background-color: #ecf0f1;
    }

    main {
      padding-top: 70px; /* Adjust based on the navbar height */
    }
  </style>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
</head>
<body>

<nav class="navbar navbar-default navbar-fixed-top">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>                        
      </button>
      <a class="navbar-brand" href="index.html">Projects</a>
    </div>
    <div class="collapse navbar-collapse" id="myNavbar">
      <ul class="nav navbar-nav">
        <li><a href="index.html">Home</a></li>
        <li><a href="hierarchical-clustering.html">Hierarchical Clustering</a></li>
        <li><a href="random-forest.html">Consumer Behaviour</a></li>
        <li><a href="pca-kmeans-clustering.html">Customer Segmentation</a></li>
      </ul>
    </div>
  </div>
</nav>

<main>
  <!-- Main content goes here -->
</main>

</body>
</html>

<div id="header">



<h1 class="title toc-ignore">Consumer Behaviour of Certified ice
Customers</h1>
<h4 class="author">Francis Ngema</h4>
<h4 class="date">2024-06-07</h4>

</div>


<style type="text/css">
  body {font-family: Montserrat, sans-serif;}
h1 {font-size: 33px;}
h1.title {font-size: 36px;}
h2 {font-size: 30px;}
h3 {font-size: 24px;}
h4 {font-size: 18px;}
h5 {font-size: 16px;}
h6 {font-size: 12px;}
 p {font-size: 16px;}
}
</style>
<div id="executive-summary" class="section level1">
<h1>Executive Summary</h1>
<p>This report presents an analysis of the factors influencing the
purchase of certified rice, using machine learning techniques to
identify key predictors. The primary objective was to understand the
significant determinants driving consumer behavior towards certified
rice.</p>
<p>The dataset, comprising various features such as perceived
self-competence in identifying certified rice (Compt), self-reported
income class (Inc), perceived psychological consequences of
environmentally friendly behavior (Env), belief that certified rice has
fewer residues compared to conventional rice (Resi), trust in the food
quality certification system (Trust), and Gender, was rigorously cleaned
and prepared. Feature selection through Recursive Feature Elimination
(RFE) with cross-validation identified the most relevant predictors,
which were then used to build and evaluate a Random Forest model.</p>
<p>The model achieved an accuracy of 84.62%, with a sensitivity of
94.12% and a specificity of 77.27%. The Area Under the ROC Curve (AUC)
was 0.9519, indicating excellent discriminative power. SHAP (SHapley
Additive exPlanations) values were used to interpret the model’s
predictions, revealing that high perceived self-competence in
identifying certified rice significantly influenced predictions
positively. Higher income levels also contributed positively to the
likelihood of purchasing certified rice, while positive perceptions of
environmentally friendly behavior had a moderate influence. The belief
that certified rice has fewer residues showed a balanced impact on
predictions, and trust in the food quality certification system
exhibited a mix of positive and negative contributions.</p>
<p>In conclusion, the study highlights the importance of perceived
competence, income, and environmental concerns in driving the purchase
of certified rice. The SHAP analysis provided valuable insights into how
these factors influence consumer behavior, offering an understanding
that can inform marketing strategies and policy decisions. The results
demonstrate that the current model is highly effective.</p>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The purpose of this exploratory data analysis was to understand the
distribution of variables in the rice dataset, identify any patterns or
trends, and gain insights into factors influencing customer decisions
regarding certified rice. This analysis was intended to guide further
studies using the Random Forest algorithm to understand customer
behavior patterns and identify key determinants of consumer
behavior.</p>
</div>
<div id="methodology" class="section level1">
<h1>Methodology</h1>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory Data Analysis</h2>
<div id="data-import-and-initial-inspection" class="section level3">
<h3>Data Import and Initial Inspection</h3>
<p>The rice dataset was imported from an Excel file. Initial inspection
of the dataset included examining the structure and summary statistics
of the variables.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Import the dataset</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">&quot;rice_dataset.xlsx&quot;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co"># Display the first few rows of the dataset</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="fu">head</span>(data)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 19
##      ID   Age Gender   Inc   Edu Child  Hhsz   Buy   Kno Compt  Sens Health
##   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     1    34      1     0     5     1     4     1     1  5     6.25   6.33
## 2     2    41      1     0     2     1     3     1     0  4.67  6      6.33
## 3     3    49      1     1     5     1    10     1     0  5.33  5.5    5   
## 4     4    47      1     0     2     1     4     1     0  4.67  6.25   6   
## 5     5    59      1     0     4     1     3     1     1  4.67  5.75   4.67
## 6     6    34      1     0     4     1     3     0     1  3.33  6.25   6.33
## # ℹ 7 more variables: Conve &lt;dbl&gt;, Price &lt;dbl&gt;, Lresi &lt;dbl&gt;, Trust &lt;dbl&gt;,
## #   Env &lt;dbl&gt;, Read &lt;dbl&gt;, Cons &lt;dbl&gt;</code></pre>
</div>
<div id="data-description" class="section level3">
<h3>Data Description</h3>
<p>The rice dataset (available at <a
href="https://data.mendeley.com/datasets/38w64m7w7t/1"
class="uri">https://data.mendeley.com/datasets/38w64m7w7t/1</a>)
comprises information gathered from participants, focusing on their
demographic characteristics, beliefs, and behaviors related to certified
rice consumption. Key variables include age, gender, education level,
income class, household size, purchase behavior of certified rice,
objective knowledge of food quality certifications, perceived competence
in identifying certified rice, beliefs regarding sensory appeal, health
benefits, convenience, value for money, and environmental consequences
of certified rice.</p>
<p>Furthermore, variables capture participants’ trust in food quality
certification systems, reading habits of food labels, and the importance
of rice in their overall diet. Overall, the dataset provides a
comprehensive snapshot of participants’ attitudes and behaviors
regarding certified rice consumption, facilitating further analysis to
uncover patterns and insights influencing consumer decisions in this
domain.</p>
<p><em>Table 1</em></p>
<table>
<colgroup>
<col width="10%" />
<col width="68%" />
<col width="21%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Description</th>
<th>Variable type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ID</td>
<td>Participant ID</td>
<td>Numeric, continuous</td>
</tr>
<tr class="even">
<td>Age</td>
<td>Age of the participant</td>
<td>Numeric, continuous</td>
</tr>
<tr class="odd">
<td>Gender</td>
<td>Gender of the participant</td>
<td>Binary</td>
</tr>
<tr class="even">
<td>Inc</td>
<td>Self-reported income class of the participant</td>
<td>Binary</td>
</tr>
<tr class="odd">
<td>Edu</td>
<td>Education of the participant</td>
<td>Categorical</td>
</tr>
<tr class="even">
<td>Child</td>
<td>Having children under 15 years of age</td>
<td>Binary</td>
</tr>
<tr class="odd">
<td>Hhsz</td>
<td>Number of household members</td>
<td>Numeric, continuous</td>
</tr>
<tr class="even">
<td>Buy</td>
<td>Participant’s purchase behavior of certified rice</td>
<td>Binary</td>
</tr>
<tr class="odd">
<td>Kno</td>
<td>Objective knowledge of food quality certifications for rice</td>
<td>Binary</td>
</tr>
<tr class="even">
<td>Compt</td>
<td>Perceived self-competence in identifying certified rice</td>
<td>Categorical</td>
</tr>
<tr class="odd">
<td>Sens</td>
<td>Belief in the sensory appeal of certified rice</td>
<td>Categorical</td>
</tr>
<tr class="even">
<td>Health</td>
<td>Belief in the health benefits of certified rice</td>
<td>Categorical</td>
</tr>
<tr class="odd">
<td>Conve</td>
<td>Belief in the convenience benefits of certified rice</td>
<td>Categorical</td>
</tr>
<tr class="even">
<td>Price</td>
<td>Belief that certified rice is good value for money</td>
<td>Categorical</td>
</tr>
<tr class="odd">
<td>Lresi</td>
<td>Belief that certified rice has much less residues compared to
conventional rice</td>
<td>Binary</td>
</tr>
<tr class="even">
<td>Trust</td>
<td>Trust in the food quality certification system for rice</td>
<td>Binary</td>
</tr>
<tr class="odd">
<td>Env</td>
<td>Perceived psychological consequences of environmentally friendly
behavior</td>
<td>Categorical</td>
</tr>
<tr class="even">
<td>Read</td>
<td>Reading of food labels while purchasing food</td>
<td>Binary</td>
</tr>
<tr class="odd">
<td>Cons</td>
<td>Importance of the food product as a staple within participant’s
overall diet</td>
<td>Binary</td>
</tr>
</tbody>
</table>
<p>This table provides a concise overview of the variables in the
dataset, their descriptions, and variable types.</p>
</div>
<div id="data-exploration-and-visualization" class="section level3">
<h3>Data Exploration and Visualization</h3>
<p>We conducted univariate analysis to explore the distribution of
individual variables. Numeric variables such as Age and Household Size
(<code>Hhsz</code>) were visualized using histograms. Categorical
variables, including <code>Gender</code>, Income Class
(<code>Inc</code>), Education Level (<code>Edu</code>), and others, were
visualised using bar plots.</p>
<p>Bivariate analysis was performed to examine relationships between
pairs of variables. This included scatter plots to analyse relationships
between numeric variables. Furthermore, box plots were utilised to
explore the relationship between numeric and categorical variables.</p>
<p>A correlation matrix for the numeric variables Age and Household Size
(<code>Hhsz</code>) was computed and visualised to understand the
relationships between these variables.</p>
</div>
<div id="summary-statistics" class="section level3">
<h3>Summary Statistics</h3>
<p>Upon inspecting the summary statistics of the rice dataset, it was
observed that some variables had missing values. The summary below
provides a glimpse into the distribution of variables, highlighting the
presence of missing values where applicable.</p>
<table>
<colgroup>
<col width="17%" />
<col width="8%" />
<col width="15%" />
<col width="13%" />
<col width="10%" />
<col width="15%" />
<col width="8%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Min</th>
<th>1st Qu.</th>
<th>Median</th>
<th>Mean</th>
<th>3rd Qu.</th>
<th>Max</th>
<th>NA’s</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ID</td>
<td>1.0</td>
<td>50.5</td>
<td>100.0</td>
<td>100.0</td>
<td>149.5</td>
<td>199.0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Age</td>
<td>25.00</td>
<td>38.00</td>
<td>45.00</td>
<td>45.38</td>
<td>53.00</td>
<td>70.00</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Gender</td>
<td>0.0000</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0.8643</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0</td>
</tr>
<tr class="even">
<td>Inc</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.4774</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Edu</td>
<td>1.000</td>
<td>3.000</td>
<td>4.000</td>
<td>NA</td>
<td>5.000</td>
<td>NA</td>
<td>0</td>
</tr>
<tr class="even">
<td>Child</td>
<td>0.0000</td>
<td>0.0000</td>
<td>1.0000</td>
<td>0.6432</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Hhsz</td>
<td>1.000</td>
<td>3.000</td>
<td>4.000</td>
<td>4.437</td>
<td>5.000</td>
<td>11.000</td>
<td>0</td>
</tr>
<tr class="even">
<td>Buy</td>
<td>0.0000</td>
<td>0.0000</td>
<td>1.0000</td>
<td>0.5226</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Kno</td>
<td>0.0000</td>
<td>0.0000</td>
<td>1.0000</td>
<td>0.6181</td>
<td>1.0000</td>
<td>1.0000</td>
<td>1</td>
</tr>
<tr class="even">
<td>Compt</td>
<td>1.330</td>
<td>3.165</td>
<td>4.670</td>
<td>4.377</td>
<td>5.330</td>
<td>7.000</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Sens</td>
<td>3.500</td>
<td>5.000</td>
<td>5.500</td>
<td>5.544</td>
<td>6.000</td>
<td>7.000</td>
<td>2</td>
</tr>
<tr class="even">
<td>Health</td>
<td>4.000</td>
<td>5.330</td>
<td>6.000</td>
<td>5.836</td>
<td>6.330</td>
<td>7.000</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Conve</td>
<td>3.000</td>
<td>3.670</td>
<td>4.330</td>
<td>4.508</td>
<td>5.000</td>
<td>7.000</td>
<td>1</td>
</tr>
<tr class="even">
<td>Price</td>
<td>2.000</td>
<td>3.000</td>
<td>5.000</td>
<td>4.535</td>
<td>6.000</td>
<td>7.000</td>
<td>1</td>
</tr>
<tr class="odd">
<td>Lresi</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.4573</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0</td>
</tr>
<tr class="even">
<td>Trust</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.2412</td>
<td>0.0000</td>
<td>1.0000</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Env</td>
<td>5.330</td>
<td>6.330</td>
<td>6.670</td>
<td>6.629</td>
<td>7.000</td>
<td>7.000</td>
<td>0</td>
</tr>
<tr class="even">
<td>Read</td>
<td>0.0000</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0.8241</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Cons</td>
<td>0.0000</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0.7889</td>
<td>1.0000</td>
<td>1.0000</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>It can be noted below that the <code>Sens</code>, <code>Conve</code>,
<code>Health</code> and <code>Price</code> variables have missing
values.<code>Health</code> has two missing values, and
<code>Sens</code>, <code>Conve</code> and <code>Price</code> have one
missing value each.</p>
<p>These missing values was handled appropriately in further analyses to
ensure the integrity and accuracy of the results. Imputation technique
were employed for handling missing values.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Display the structure of the dataset</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="fu">str</span>(data)</span></code></pre></div>
<pre><code>## tibble [199 × 19] (S3: tbl_df/tbl/data.frame)
##  $ ID    : num [1:199] 1 2 3 4 5 6 7 8 9 10 ...
##  $ Age   : num [1:199] 34 41 49 47 59 34 43 54 53 52 ...
##  $ Gender: num [1:199] 1 1 1 1 1 1 1 1 1 0 ...
##  $ Inc   : num [1:199] 0 0 1 0 0 0 1 0 1 1 ...
##  $ Edu   : num [1:199] 5 2 5 2 4 4 2 2 4 2 ...
##  $ Child : num [1:199] 1 1 1 1 1 1 1 0 1 1 ...
##  $ Hhsz  : num [1:199] 4 3 10 4 3 3 7 3 4 7 ...
##  $ Buy   : num [1:199] 1 1 1 1 1 0 1 1 1 0 ...
##  $ Kno   : num [1:199] 1 0 0 0 1 1 1 1 0 1 ...
##  $ Compt : num [1:199] 5 4.67 5.33 4.67 4.67 3.33 6.33 5.67 4 4.67 ...
##  $ Sens  : num [1:199] 6.25 6 5.5 6.25 5.75 6.25 6.25 6.25 5.5 5 ...
##  $ Health: num [1:199] 6.33 6.33 5 6 4.67 6.33 6.67 6.33 6 6.67 ...
##  $ Conve : num [1:199] 6 4 5 4.33 3.67 4 5 5.67 5 5.33 ...
##  $ Price : num [1:199] 6 6 6 6 5 4 4 6 6 5 ...
##  $ Lresi : num [1:199] 1 1 0 1 0 0 0 1 1 1 ...
##  $ Trust : num [1:199] 0 0 0 0 0 0 1 0 0 0 ...
##  $ Env   : num [1:199] 6.33 7 6 6.67 6 7 6.67 6 7 6.33 ...
##  $ Read  : num [1:199] 1 1 1 1 1 1 1 0 1 1 ...
##  $ Cons  : num [1:199] 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Glimpse of the dataset</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="fu">glimpse</span>(data)</span></code></pre></div>
<pre><code>## Rows: 199
## Columns: 19
## $ ID     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …
## $ Age    &lt;dbl&gt; 34, 41, 49, 47, 59, 34, 43, 54, 53, 52, 50, 29, 26, 59, 31, 26,…
## $ Gender &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, …
## $ Inc    &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, …
## $ Edu    &lt;dbl&gt; 5, 2, 5, 2, 4, 4, 2, 2, 4, 2, 1, 5, 5, 3, 1, 5, 5, 3, 5, 5, 4, …
## $ Child  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, …
## $ Hhsz   &lt;dbl&gt; 4, 3, 10, 4, 3, 3, 7, 3, 4, 7, 6, 7, 6, 2, 3, 7, 4, 6, 2, 3, 5,…
## $ Buy    &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, …
## $ Kno    &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …
## $ Compt  &lt;dbl&gt; 5.00, 4.67, 5.33, 4.67, 4.67, 3.33, 6.33, 5.67, 4.00, 4.67, 5.0…
## $ Sens   &lt;dbl&gt; 6.25, 6.00, 5.50, 6.25, 5.75, 6.25, 6.25, 6.25, 5.50, 5.00, 5.7…
## $ Health &lt;dbl&gt; 6.33, 6.33, 5.00, 6.00, 4.67, 6.33, 6.67, 6.33, 6.00, 6.67, 7.0…
## $ Conve  &lt;dbl&gt; 6.00, 4.00, 5.00, 4.33, 3.67, 4.00, 5.00, 5.67, 5.00, 5.33, 4.6…
## $ Price  &lt;dbl&gt; 6, 6, 6, 6, 5, 4, 4, 6, 6, 5, 5, 6, 4, 4, 3, 3, 5, 4, 3, 6, 6, …
## $ Lresi  &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …
## $ Trust  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
## $ Env    &lt;dbl&gt; 6.33, 7.00, 6.00, 6.67, 6.00, 7.00, 6.67, 6.00, 7.00, 6.33, 6.0…
## $ Read   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …
## $ Cons   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Display summary statistics</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##        ID             Age            Gender            Inc        
##  Min.   :  1.0   Min.   :25.00   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.: 50.5   1st Qu.:38.00   1st Qu.:1.0000   1st Qu.:0.0000  
##  Median :100.0   Median :45.00   Median :1.0000   Median :0.0000  
##  Mean   :100.0   Mean   :45.38   Mean   :0.8643   Mean   :0.4774  
##  3rd Qu.:149.5   3rd Qu.:53.00   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :199.0   Max.   :70.00   Max.   :1.0000   Max.   :1.0000  
##                                                                   
##       Edu            Child             Hhsz             Buy        
##  Min.   :1.000   Min.   :0.0000   Min.   : 1.000   Min.   :0.0000  
##  1st Qu.:3.000   1st Qu.:0.0000   1st Qu.: 3.000   1st Qu.:0.0000  
##  Median :4.000   Median :1.0000   Median : 4.000   Median :1.0000  
##  Mean   :3.608   Mean   :0.6432   Mean   : 4.437   Mean   :0.5226  
##  3rd Qu.:5.000   3rd Qu.:1.0000   3rd Qu.: 5.000   3rd Qu.:1.0000  
##  Max.   :5.000   Max.   :1.0000   Max.   :11.000   Max.   :1.0000  
##                                                                    
##       Kno             Compt            Sens           Health     
##  Min.   :0.0000   Min.   :1.330   Min.   :3.500   Min.   :4.000  
##  1st Qu.:0.0000   1st Qu.:3.165   1st Qu.:5.000   1st Qu.:5.330  
##  Median :1.0000   Median :4.670   Median :5.500   Median :6.000  
##  Mean   :0.6181   Mean   :4.377   Mean   :5.544   Mean   :5.836  
##  3rd Qu.:1.0000   3rd Qu.:5.330   3rd Qu.:6.000   3rd Qu.:6.330  
##  Max.   :1.0000   Max.   :7.000   Max.   :7.000   Max.   :7.000  
##                                   NA&#39;s   :1       NA&#39;s   :2      
##      Conve           Price           Lresi            Trust       
##  Min.   :3.000   Min.   :2.000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:3.670   1st Qu.:3.000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :4.330   Median :5.000   Median :0.0000   Median :0.0000  
##  Mean   :4.508   Mean   :4.535   Mean   :0.4573   Mean   :0.2412  
##  3rd Qu.:5.000   3rd Qu.:6.000   3rd Qu.:1.0000   3rd Qu.:0.0000  
##  Max.   :7.000   Max.   :7.000   Max.   :1.0000   Max.   :1.0000  
##  NA&#39;s   :1       NA&#39;s   :1                                        
##       Env             Read             Cons       
##  Min.   :5.330   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:6.330   1st Qu.:1.0000   1st Qu.:1.0000  
##  Median :6.670   Median :1.0000   Median :1.0000  
##  Mean   :6.629   Mean   :0.8241   Mean   :0.7889  
##  3rd Qu.:7.000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :7.000   Max.   :1.0000   Max.   :1.0000  
## </code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Check for missing values in each column</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="fu">colSums</span>(<span class="fu">is.na</span>(data))</span></code></pre></div>
<pre><code>##     ID    Age Gender    Inc    Edu  Child   Hhsz    Buy    Kno  Compt   Sens 
##      0      0      0      0      0      0      0      0      0      0      1 
## Health  Conve  Price  Lresi  Trust    Env   Read   Cons 
##      2      1      1      0      0      0      0      0</code></pre>
</div>
<div id="univariate-analysis-of-numeric-variables"
class="section level3">
<h3>Univariate Analysis of Numeric Variables</h3>
<p><em>Distribution of Numeric Variables</em></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># Plot histograms for numeric variables</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>numeric_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Hhsz&quot;</span>)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>data <span class="sc">%&gt;%</span> <span class="fu">select</span>(numeric_vars) <span class="sc">%&gt;%</span> </span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> <span class="st">&quot;variable&quot;</span>, <span class="at">value =</span> <span class="st">&quot;value&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> value)) <span class="sc">+</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>, <span class="at">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> variable, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Distribution of Numeric Variables&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The distribution analysis of numerical variables in the rice dataset,
focusing on Age and Number of household members (Hhsz), reveals insights
into the shape, center, and spread of the data.</p>
<p><em>Shape of the Distribution:</em> The left histogram representing
Age appears to be unimodal and roughly symmetric. Most values cluster
around 50, with a spread between approximately 40 and 64. In contrast,
the right histogram depicting the Number of household members (Hhsz) is
also unimodal but exhibits a more pronounced peak around a specific
value, indicating a stronger central tendency.</p>
<p><em>Central Tendency:</em> The center of the data in the left
histogram, representing Age, is near 50, suggesting that the median or
mean age of participants is around this value. For the right histogram,
the peak indicates the central value (mean or median) around which most
data points are concentrated, providing insight into the typical size of
households among participants.</p>
<p><em>Variability:</em> The spread in the left histogram covering a
wider range (40 to 64) suggests greater variability in ages among
participants. Conversely, the right histogram displays less spread, with
values concentrated around a specific point, indicating less variability
in the number of household members among participants.</p>
</div>
<div id="univariate-analysis-of-categorical-variables"
class="section level3">
<h3>Univariate Analysis of Categorical Variables</h3>
<p><em>Distribution of Categorical Variables</em></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># Plot bar plots for categorical variables</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>categorical_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Gender&quot;</span>, <span class="st">&quot;Inc&quot;</span>, <span class="st">&quot;Edu&quot;</span>, <span class="st">&quot;Child&quot;</span>, <span class="st">&quot;Buy&quot;</span>, <span class="st">&quot;Kno&quot;</span>, <span class="st">&quot;Compt&quot;</span>, <span class="st">&quot;Sens&quot;</span>, <span class="st">&quot;Health&quot;</span>, <span class="st">&quot;Conve&quot;</span>, <span class="st">&quot;Price&quot;</span>, <span class="st">&quot;Lresi&quot;</span>, <span class="st">&quot;Trust&quot;</span>, <span class="st">&quot;Env&quot;</span>, <span class="st">&quot;Read&quot;</span>, <span class="st">&quot;Cons&quot;</span>)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>data <span class="sc">%&gt;%</span> <span class="fu">select</span>(categorical_vars) <span class="sc">%&gt;%</span> </span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> <span class="st">&quot;variable&quot;</span>, <span class="at">value =</span> <span class="st">&quot;value&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> value, <span class="at">fill =</span> variable)) <span class="sc">+</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">position =</span> <span class="st">&quot;dodge&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> variable, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Distribution of Categorical Variables&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-4-1.png" width="672" />
The distribution analysis of variables within the rice dataset reveals
notable trends and insights into participants’ behaviors and attitudes
towards certified rice consumption.</p>
<p>A significant portion of participants demonstrate regular purchasing
behavior of certified rice, as evidenced by peaks in the distribution
around 100 for those who purchased and lower values for those who did
not. This indicates a potential market for certified rice products.</p>
<p>The distribution of participants having children under 15 years of
age leans towards a higher proportion with children in this age group.
This demographic factor may influence buying habits or consumption
patterns, particularly regarding bulk purchases of rice.</p>
<p>Perceived competence in identifying certified rice tends to center
around the 4-5 range, suggesting moderate confidence levels among
participants. This highlights a potential opportunity for educational
interventions to enhance participant certainty in identifying certified
rice products.</p>
<p>Consumption patterns reveal that rice is considered an important
daily staple for many participants, with a peak around 150. This
underscores the significance of rice as a staple food within the diet of
a substantial group of participants.</p>
<p>Convenience beliefs regarding certified rice exhibit variation, with
some participants valuing convenience more highly than others. This
diversity suggests the importance of tailored marketing strategies that
address both preferences, emphasizing convenience benefits for some
while focusing on other aspects like health or environmental impact for
others.</p>
<p>The distribution of education levels within the dataset reflects
diversity, with the majority falling within high school, higher
education other than university, and university categories. This
underscores the importance of considering participants’ educational
backgrounds when designing communication or educational materials.</p>
<p>Awareness of environmental consequences associated with rice
production varies among participants, highlighting the need for targeted
interventions to raise awareness about the environmental impact of rice
production choices.</p>
<p>The gender distribution shows a predominantly female representation
within the dataset, indicating a gender imbalance among
participants.</p>
<p>Beliefs regarding the health benefits of certified rice exhibit
variation, with peaks around different values. This emphasizes the
importance of understanding diverse perceptions when promoting certified
rice, as some participants may prioritize health benefits more highly
than others.</p>
<p>Income class distribution indicates a balance between upper-class and
lower-income participants, suggesting a mix of income levels within the
dataset.</p>
<p>A higher proportion of participants demonstrate objective knowledge
of food quality certifications, indicating a level of familiarity and
awareness among the participants.</p>
<p>Trust in food quality certification systems varies among
participants, with some exhibiting high levels of trust while others
express lower confidence. Understanding these variations can inform
efforts to build trust and encourage participation in the certified rice
market.</p>
<p>These observations depict diverse perspectives and behaviors
regarding certified rice consumption.</p>
</div>
<div id="bivariate-analysis-numeric-vs-numeric" class="section level3">
<h3>Bivariate Analysis (Numeric vs Numeric)</h3>
<p><em>Scatter plot of Age vs Household Size</em></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Scatter plot between Age and Hhsz</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> Age, <span class="at">y =</span> Hhsz)) <span class="sc">+</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatter plot of Age vs Household Size&quot;</span>,</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Age&quot;</span>,</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Household Size&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-5-1.png" width="672" />
The scatter plot illustrates a notable trend indicating that as age
increases, there is a decrease in the number of household members. This
observation suggests a negative correlation between age and household
size. For instance, at an age of 70, there appears to be a reduced
number of household members compared to younger ages. This trend implies
that as individuals age, they may have fewer dependents or family
members living with them, which could be influenced by various factors
such as children leaving home, changes in family structure, or lifestyle
choices.</p>
</div>
<div id="bivariate-analysis-numeric-vs-categorical"
class="section level3">
<h3>Bivariate Analysis (Numeric vs Categorical)</h3>
<p><em>Age Distribution by Purchase Behaviour</em></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># Box plot of Age by Buy</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">as.factor</span>(Buy), <span class="at">y =</span> Age)) <span class="sc">+</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Box plot of Age by Purchase Behaviour&quot;</span>,</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Purchase Behavior (Buy)&quot;</span>,</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Age&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-6-1.png" width="672" />
The box plot shows the distribution of participant ages across two
groups: those who buy certified rice (<code>Buy</code> = 1) and those
who do not (<code>Buy</code> = 0).</p>
<p>While the median age is slightly lower for those who do not buy
certified rice, the overall distribution indicates that certified rice
is purchased by people across a variety of age groups. There is no
strong separation between the two groups, suggesting that age may not be
a defining factor when it comes to buying certified rice.</p>
</div>
<div id="bivariate-analysis-categorical-vs-categorical"
class="section level3">
<h3>Bivariate Analysis (Categorical vs Categorical)</h3>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># Contingency table of Gender and Buy</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="fu">table</span>(data<span class="sc">$</span>Gender, data<span class="sc">$</span>Buy)</span></code></pre></div>
<pre><code>##    
##      0  1
##   0 15 12
##   1 80 92</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co"># Bar plot of Gender by Buy</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">as.factor</span>(Gender), <span class="at">fill =</span> <span class="fu">as.factor</span>(Buy))) <span class="sc">+</span></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Bar plot of Gender by Purchase Behavior&quot;</span>,</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Gender&quot;</span>,</span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;Purchase Behavior (Buy)&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-7-1.png" width="672" />
The bar plot indicates some associations between <code>Gender</code> and
<code>Buy</code> . For instance, a higher proportion of females
purchased certified rice compared to males.</p>
</div>
<div id="correlation-matrix" class="section level3">
<h3>Correlation Matrix</h3>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># Compute correlation matrix for numeric variables</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>numeric_data <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(Age, Hhsz)</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(numeric_data, <span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>)</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="co"># Print the correlation matrix</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a><span class="fu">print</span>(cor_matrix)</span></code></pre></div>
<pre><code>##              Age        Hhsz
## Age   1.00000000 -0.04438532
## Hhsz -0.04438532  1.00000000</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="co"># Visualize the correlation matrix</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="fu">ggcorrplot</span>(cor_matrix, <span class="at">method =</span> <span class="st">&quot;circle&quot;</span>, <span class="at">lab =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-8-1.png" width="672" />
The correlation analysis between the variables <code>Age</code> and
<code>Hhsz</code> reveals a weak negative relationship, indicating that
as age increases, there is a corresponding decrease in the number of
household members. This finding corroborates previous observations made
regarding the inverse association between age and household size.</p>
</div>
</div>
<div id="data-preprocessing" class="section level2">
<h2>Data Preprocessing</h2>
<div id="handling-missing-data" class="section level3">
<h3>Handling Missing Data</h3>
<p>Following an assessment of missing values within the dataset, it was
observed that the variables <code>Sens</code>, <code>Conve</code>,
<code>Health</code>, and <code>Price</code> contained missing values.
Specifically, <code>Health</code> exhibited two missing values, while
<code>Sens</code>, <code>Conve</code>, and <code>Price</code> each had
one missing value.</p>
<p>To address these missing values, a mode imputation strategy was
employed for the categorical variables (<code>Sens</code>,
<code>Conve</code>, <code>Health</code>, and <code>Price</code>). The
mode, representing the most frequently occurring value within each
respective variable, was calculated and used to replace the missing
values.</p>
<p>Following the imputation process, the imputed values were combined
with the original dataset. The old columns containing missing values
(<code>Sens</code>, <code>Conve</code>, <code>Health</code>, and
<code>Price</code>) were subsequently dropped from the combined dataset,
resulting in a cleaned dataset ready for analysis.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="co"># Define a function to calculate mode</span></span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>get_mode <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>  unique_x <span class="ot">&lt;-</span> <span class="fu">unique</span>(x)</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>  unique_x[<span class="fu">which.max</span>(<span class="fu">tabulate</span>(<span class="fu">match</span>(x, unique_x)))]</span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a>}</span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a><span class="co"># Imputation Strategy: Mode Imputation for categorical variables</span></span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a>imputed_values <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span></span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Sens =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(Sens), <span class="fu">get_mode</span>(data<span class="sc">$</span>Sens), Sens),</span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a>         <span class="at">Conve =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(Conve), <span class="fu">get_mode</span>(data<span class="sc">$</span>Conve), Conve),</span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a>         <span class="at">Health =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(Health), <span class="fu">get_mode</span>(data<span class="sc">$</span>Health), Health),</span>
<span id="cb21-12"><a href="#cb21-12" tabindex="-1"></a>         <span class="at">Price =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(Price), <span class="fu">get_mode</span>(data<span class="sc">$</span>Price), Price))</span>
<span id="cb21-13"><a href="#cb21-13" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" tabindex="-1"></a><span class="co"># Combine imputed data with original dataset</span></span>
<span id="cb21-15"><a href="#cb21-15" tabindex="-1"></a>combined_data <span class="ot">&lt;-</span> <span class="fu">cbind</span>(data[, <span class="sc">!</span><span class="fu">names</span>(data) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Sens&quot;</span>, <span class="st">&quot;Conve&quot;</span>, <span class="st">&quot;Health&quot;</span>, <span class="st">&quot;Price&quot;</span>)],</span>
<span id="cb21-16"><a href="#cb21-16" tabindex="-1"></a>                        imputed_values[, <span class="fu">c</span>(<span class="st">&quot;Sens&quot;</span>, <span class="st">&quot;Conve&quot;</span>, <span class="st">&quot;Health&quot;</span>, <span class="st">&quot;Price&quot;</span>)])</span>
<span id="cb21-17"><a href="#cb21-17" tabindex="-1"></a></span>
<span id="cb21-18"><a href="#cb21-18" tabindex="-1"></a><span class="co"># Drop old columns with missing values</span></span>
<span id="cb21-19"><a href="#cb21-19" tabindex="-1"></a>cleaned_data <span class="ot">&lt;-</span> combined_data <span class="sc">%&gt;%</span></span>
<span id="cb21-20"><a href="#cb21-20" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">matches</span>(<span class="st">&quot;Sens|Conve|Health|Price&quot;</span>))</span>
<span id="cb21-21"><a href="#cb21-21" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" tabindex="-1"></a><span class="co"># View the cleaned dataset</span></span>
<span id="cb21-23"><a href="#cb21-23" tabindex="-1"></a><span class="fu">head</span>(cleaned_data)</span></code></pre></div>
<pre><code>##   ID Age Gender Inc Edu Child Hhsz Buy Kno Compt Lresi Trust  Env Read Cons
## 1  1  34      1   0   5     1    4   1   1  5.00     1     0 6.33    1    1
## 2  2  41      1   0   2     1    3   1   0  4.67     1     0 7.00    1    1
## 3  3  49      1   1   5     1   10   1   0  5.33     0     0 6.00    1    1
## 4  4  47      1   0   2     1    4   1   0  4.67     1     0 6.67    1    1
## 5  5  59      1   0   4     1    3   1   1  4.67     0     0 6.00    1    1
## 6  6  34      1   0   4     1    3   0   1  3.33     0     0 7.00    1    1</code></pre>
</div>
<div id="age-categorisation-and-encoding" class="section level3">
<h3>Age Categorisation and Encoding</h3>
<p>The <code>Age</code> variable in the dataset was categorised into
four distinct age groups to facilitate analysis. These categories were
then encoded numerically for ease of use in statistical analysis and
machine learning models. The defined and encoded categories are as
follows:</p>
<p><em>Young Adults (25-34 years):</em> Encoded as 1. This group
represents younger participants who are at the early stages of their
adult life. <em>Middle-aged Adults (35-49 years):</em> Encoded as 2.
This category includes participants who are in the middle phase of their
adult life, often associated with peak career years and family
responsibilities. <em>Older Adults (50-64 years):</em> Encoded as 3.
Participants in this group are approaching retirement age and may have
different consumption patterns and health considerations. <em>Seniors
(65+ years):</em> Encoded as 4. This category includes participants who
are in the senior phase of their life, typically retired, with
potentially different purchasing behaviors and preferences.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="co"># Define age categories and encode them</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>cleaned_data <span class="ot">&lt;-</span> cleaned_data <span class="sc">%&gt;%</span></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Age_Category =</span> <span class="fu">cut</span>(Age,</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>                            <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">24</span>, <span class="dv">34</span>, <span class="dv">49</span>, <span class="dv">64</span>, <span class="cn">Inf</span>),</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>                            <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Young Adults (25-34)&quot;</span>, <span class="st">&quot;Middle-aged Adults (35-49)&quot;</span>, <span class="st">&quot;Older Adults (50-64)&quot;</span>, <span class="st">&quot;Seniors (65+)&quot;</span>),</span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a>                            <span class="at">right =</span> <span class="cn">FALSE</span>),</span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a>         <span class="at">Age_Category_Encoded =</span> <span class="fu">as.integer</span>(<span class="fu">factor</span>(Age_Category, </span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a>                                                  <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Young Adults (25-34)&quot;</span>, <span class="st">&quot;Middle-aged Adults (35-49)&quot;</span>, <span class="st">&quot;Older Adults (50-64)&quot;</span>, <span class="st">&quot;Seniors (65+)&quot;</span>))))</span>
<span id="cb23-9"><a href="#cb23-9" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" tabindex="-1"></a><span class="co"># View the first few rows to check the new Age_Category_Encoded column</span></span>
<span id="cb23-11"><a href="#cb23-11" tabindex="-1"></a><span class="fu">head</span>(cleaned_data)</span></code></pre></div>
<pre><code>##   ID Age Gender Inc Edu Child Hhsz Buy Kno Compt Lresi Trust  Env Read Cons
## 1  1  34      1   0   5     1    4   1   1  5.00     1     0 6.33    1    1
## 2  2  41      1   0   2     1    3   1   0  4.67     1     0 7.00    1    1
## 3  3  49      1   1   5     1   10   1   0  5.33     0     0 6.00    1    1
## 4  4  47      1   0   2     1    4   1   0  4.67     1     0 6.67    1    1
## 5  5  59      1   0   4     1    3   1   1  4.67     0     0 6.00    1    1
## 6  6  34      1   0   4     1    3   0   1  3.33     0     0 7.00    1    1
##                 Age_Category Age_Category_Encoded
## 1 Middle-aged Adults (35-49)                    2
## 2 Middle-aged Adults (35-49)                    2
## 3       Older Adults (50-64)                    3
## 4 Middle-aged Adults (35-49)                    2
## 5       Older Adults (50-64)                    3
## 6 Middle-aged Adults (35-49)                    2</code></pre>
</div>
<div id="drop-unnecessary-columns" class="section level3">
<h3>Drop Unnecessary Columns</h3>
<p>In preparing the dataset for analysis, the <code>ID</code>,
<code>Age</code>, and <code>Age_Category</code> columns were removed.
This decision was made to streamline the dataset and focus on the
variables that are most pertinent to the analysis objectives. The ID
column, being a unique identifier for each participant, did not add
analytical value. The <code>Age</code> and <code>Age_Category</code>
columns were removed to avoid redundancy, given that the
<code>Age_Category_Encoded</code> column now effectively captures the
relevant age information in a numerical format suitable for
analysis.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="co"># Drop ID, Age, and Age_Category columns</span></span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>cleaned_data <span class="ot">&lt;-</span> cleaned_data <span class="sc">%&gt;%</span></span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>ID, <span class="sc">-</span>Age, <span class="sc">-</span>Age_Category)</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a><span class="co"># View the first few rows to check the updated dataset</span></span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a><span class="fu">head</span>(cleaned_data)</span></code></pre></div>
<pre><code>##   Gender Inc Edu Child Hhsz Buy Kno Compt Lresi Trust  Env Read Cons
## 1      1   0   5     1    4   1   1  5.00     1     0 6.33    1    1
## 2      1   0   2     1    3   1   0  4.67     1     0 7.00    1    1
## 3      1   1   5     1   10   1   0  5.33     0     0 6.00    1    1
## 4      1   0   2     1    4   1   0  4.67     1     0 6.67    1    1
## 5      1   0   4     1    3   1   1  4.67     0     0 6.00    1    1
## 6      1   0   4     1    3   0   1  3.33     0     0 7.00    1    1
##   Age_Category_Encoded
## 1                    2
## 2                    2
## 3                    3
## 4                    2
## 5                    3
## 6                    2</code></pre>
</div>
<div id="feature-scaling-of-hhsz" class="section level3">
<h3>Feature Scaling of Hhsz</h3>
<p>Feature scaling was applied to the <code>Hhsz</code> (number of
household members) variable to standardise its values. This involved
transforming the variable to have a mean of 0 and a standard deviation
of 1. The standardised Hhsz variable, now represented as Hhsz_Scaled,
ensures that the feature is on a similar scale as other variables in the
dataset, which is crucial for many machine learning algorithms to
perform effectively.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="co"># Standardize the Hhsz variable</span></span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>cleaned_data <span class="ot">&lt;-</span> cleaned_data <span class="sc">%&gt;%</span></span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Hhsz_Scaled =</span> <span class="fu">scale</span>(Hhsz)) <span class="sc">%&gt;%</span></span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>Hhsz)  <span class="co"># Drop the original Hhsz column</span></span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a><span class="co"># View the first few rows to check the updated dataset</span></span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a><span class="fu">head</span>(cleaned_data)</span></code></pre></div>
<pre><code>##   Gender Inc Edu Child Buy Kno Compt Lresi Trust  Env Read Cons
## 1      1   0   5     1   1   1  5.00     1     0 6.33    1    1
## 2      1   0   2     1   1   0  4.67     1     0 7.00    1    1
## 3      1   1   5     1   1   0  5.33     0     0 6.00    1    1
## 4      1   0   2     1   1   0  4.67     1     0 6.67    1    1
## 5      1   0   4     1   1   1  4.67     0     0 6.00    1    1
## 6      1   0   4     1   0   1  3.33     0     0 7.00    1    1
##   Age_Category_Encoded Hhsz_Scaled
## 1                    2  -0.2547872
## 2                    2  -0.8375763
## 3                    3   3.2419474
## 4                    2  -0.2547872
## 5                    3  -0.8375763
## 6                    2  -0.8375763</code></pre>
</div>
<div id="feature-selection" class="section level3">
<h3>Feature Selection</h3>
<p>Recursive Feature Elimination (RFE) was performed to identify the
most important features influencing the purchase behavior of certified
rice. Using cross-validation, the optimal subset of features was
selected to improve the model’s predictive performance. Please refer to
the output below.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="co"># Set up control for RFE</span></span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">rfeControl</span>(<span class="at">functions=</span>rfFuncs, <span class="at">method=</span><span class="st">&quot;cv&quot;</span>, <span class="at">number=</span><span class="dv">10</span>)</span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a><span class="co"># Define the predictor variables and the response variable</span></span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a>predictors <span class="ot">&lt;-</span> cleaned_data[, <span class="sc">!</span><span class="fu">names</span>(cleaned_data) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Buy&quot;</span>)]</span>
<span id="cb29-6"><a href="#cb29-6" tabindex="-1"></a>response <span class="ot">&lt;-</span> cleaned_data<span class="sc">$</span>Buy</span>
<span id="cb29-7"><a href="#cb29-7" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" tabindex="-1"></a><span class="co"># Perform RFE</span></span>
<span id="cb29-9"><a href="#cb29-9" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb29-10"><a href="#cb29-10" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">rfe</span>(predictors, response, <span class="at">sizes=</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(predictors)), <span class="at">rfeControl=</span>control)</span>
<span id="cb29-11"><a href="#cb29-11" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb29-13"><a href="#cb29-13" tabindex="-1"></a><span class="fu">print</span>(results)</span></code></pre></div>
<pre><code>## 
## Recursive feature selection
## 
## Outer resampling method: Cross-Validated (10 fold) 
## 
## Resampling performance over subset size:
## 
##  Variables   RMSE Rsquared    MAE  RMSESD RsquaredSD   MAESD Selected
##          1 0.4420   0.2472 0.3701 0.05112    0.13388 0.03912         
##          2 0.4390   0.2442 0.3940 0.03993    0.12500 0.03501         
##          3 0.4342   0.2740 0.3988 0.04267    0.18356 0.03557         
##          4 0.4363   0.2774 0.4046 0.03742    0.17218 0.03095         
##          5 0.4358   0.2756 0.4060 0.03211    0.13965 0.03037         
##          6 0.4330   0.2679 0.3682 0.04593    0.11238 0.03586        *
##          7 0.4352   0.2574 0.3758 0.03742    0.10674 0.02923         
##          8 0.4360   0.2547 0.3814 0.03926    0.12287 0.03068         
##          9 0.4403   0.2430 0.3763 0.04379    0.12389 0.03293         
##         10 0.4378   0.2518 0.3785 0.04514    0.12242 0.03511         
##         11 0.4378   0.2470 0.3823 0.04085    0.10558 0.03213         
##         12 0.4412   0.2341 0.3822 0.03829    0.09765 0.02966         
##         13 0.4356   0.2527 0.3799 0.03932    0.10873 0.03162         
## 
## The top 5 variables (out of 6):
##    Compt, Inc, Lresi, Env, Gender</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="co"># List the chosen features</span></span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>chosen_features <span class="ot">&lt;-</span> predictors[, <span class="fu">predictors</span>(results)]</span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a><span class="fu">print</span>(chosen_features)</span></code></pre></div>
<pre><code>##     Compt Inc Lresi  Env Gender Trust
## 1    5.00   0     1 6.33      1     0
## 2    4.67   0     1 7.00      1     0
## 3    5.33   1     0 6.00      1     0
## 4    4.67   0     1 6.67      1     0
## 5    4.67   0     0 6.00      1     0
## 6    3.33   0     0 7.00      1     0
## 7    6.33   1     0 6.67      1     1
## 8    5.67   0     1 6.00      1     0
## 9    4.00   1     1 7.00      1     0
## 10   4.67   1     1 6.33      0     0
## 11   5.00   1     0 6.00      1     0
## 12   6.00   1     0 6.00      1     1
## 13   6.00   1     0 7.00      1     0
## 14   3.67   1     0 7.00      0     0
## 15   3.00   0     0 7.00      1     0
## 16   4.33   0     0 6.00      1     0
## 17   6.00   0     0 7.00      1     0
## 18   4.33   0     0 6.00      1     0
## 19   6.67   1     0 6.67      1     0
## 20   5.67   1     1 6.33      1     0
## 21   5.33   0     0 7.00      1     0
## 22   2.33   1     0 6.67      1     0
## 23   4.67   1     0 7.00      1     0
## 24   3.00   1     1 7.00      1     0
## 25   2.67   0     0 6.67      1     0
## 26   4.00   0     1 6.67      1     0
## 27   2.33   1     1 5.67      1     0
## 28   4.33   0     1 6.33      1     1
## 29   4.67   1     0 7.00      1     0
## 30   2.67   1     0 6.33      0     0
## 31   6.33   1     1 6.00      0     1
## 32   2.67   1     0 7.00      1     1
## 33   3.67   1     1 6.00      0     0
## 34   4.33   0     1 7.00      1     0
## 35   1.67   0     1 6.67      1     0
## 36   6.00   1     1 7.00      1     1
## 37   7.00   1     1 6.00      1     1
## 38   5.00   0     1 7.00      1     0
## 39   5.67   0     0 6.67      0     0
## 40   5.33   0     1 6.67      0     0
## 41   4.67   1     1 7.00      0     1
## 42   2.33   1     0 6.00      1     0
## 43   2.67   1     0 7.00      1     1
## 44   3.33   0     0 7.00      1     0
## 45   2.33   0     0 7.00      1     0
## 46   6.00   0     1 6.67      1     0
## 47   4.33   1     1 6.00      1     1
## 48   5.00   0     1 6.00      1     0
## 49   2.33   0     0 6.67      1     0
## 50   5.67   1     1 7.00      1     0
## 51   5.00   0     0 7.00      0     0
## 52   4.33   1     1 6.67      1     0
## 53   5.67   0     1 6.67      1     0
## 54   5.67   1     1 7.00      1     1
## 55   3.67   0     0 7.00      1     1
## 56   4.00   0     0 6.33      1     0
## 57   6.33   1     1 7.00      1     0
## 58   6.00   1     1 6.67      1     1
## 59   6.00   0     1 6.33      1     0
## 60   5.00   1     0 6.67      1     0
## 61   4.33   0     0 6.00      1     0
## 62   1.33   0     0 7.00      1     0
## 63   5.33   1     1 7.00      1     1
## 64   7.00   1     1 7.00      1     0
## 65   5.00   1     0 5.67      1     0
## 66   6.00   0     0 6.67      1     0
## 67   5.00   1     1 6.00      1     1
## 68   1.67   0     0 6.67      1     0
## 69   2.67   1     0 6.00      1     1
## 70   3.67   0     0 7.00      1     0
## 71   4.67   0     1 6.67      1     0
## 72   5.67   1     1 6.00      1     0
## 73   2.33   0     1 7.00      0     1
## 74   5.67   0     1 6.33      0     0
## 75   5.67   0     1 7.00      1     1
## 76   2.00   0     1 7.00      1     0
## 77   3.00   0     1 6.00      1     0
## 78   5.00   1     0 6.67      1     0
## 79   7.00   1     1 6.00      1     0
## 80   3.67   0     1 6.33      1     1
## 81   4.67   1     0 6.00      1     0
## 82   2.00   0     0 6.67      1     0
## 83   6.33   1     0 6.67      1     0
## 84   6.00   0     0 5.33      1     0
## 85   2.67   0     0 6.67      0     1
## 86   6.00   1     0 7.00      0     0
## 87   5.33   1     1 7.00      1     1
## 88   4.67   0     0 6.00      1     0
## 89   5.33   1     1 7.00      1     1
## 90   6.00   0     1 7.00      0     0
## 91   1.67   1     0 5.67      0     0
## 92   6.33   0     1 6.33      1     1
## 93   5.00   0     0 7.00      1     0
## 94   7.00   0     1 7.00      1     0
## 95   5.00   1     1 6.67      1     0
## 96   4.00   0     1 7.00      1     0
## 97   3.33   0     0 5.67      1     0
## 98   2.33   1     0 7.00      1     0
## 99   3.67   0     0 6.00      1     0
## 100  6.33   1     1 6.33      1     1
## 101  2.67   0     0 6.67      1     0
## 102  4.00   1     1 6.67      0     0
## 103  3.00   1     0 6.33      1     0
## 104  4.67   0     0 7.00      1     0
## 105  5.67   1     0 7.00      1     1
## 106  6.00   0     1 6.67      1     0
## 107  4.33   0     1 6.67      1     0
## 108  4.67   0     0 7.00      1     0
## 109  3.33   1     1 6.67      1     1
## 110  4.33   1     0 6.67      1     1
## 111  4.00   1     1 6.00      1     0
## 112  4.67   1     0 7.00      1     0
## 113  4.00   1     1 7.00      1     0
## 114  2.67   1     0 6.33      1     0
## 115  6.67   1     1 7.00      1     0
## 116  3.67   0     0 6.67      1     1
## 117  3.00   1     0 6.67      1     0
## 118  2.67   0     0 6.67      1     1
## 119  2.00   0     0 7.00      0     0
## 120  4.33   1     0 7.00      0     0
## 121  5.33   1     1 6.67      1     0
## 122  5.00   0     0 6.33      1     0
## 123  4.33   0     1 7.00      1     1
## 124  2.33   0     0 6.67      0     0
## 125  2.33   0     1 7.00      1     0
## 126  5.33   0     1 7.00      1     0
## 127  2.33   0     0 6.67      1     0
## 128  5.00   0     0 6.00      1     0
## 129  4.67   1     0 7.00      1     1
## 130  5.00   1     0 7.00      1     1
## 131  4.33   0     1 6.33      1     0
## 132  3.33   0     0 6.33      1     0
## 133  7.00   1     1 7.00      1     1
## 134  2.67   1     0 6.67      1     0
## 135  5.33   0     0 7.00      1     0
## 136  3.00   0     0 6.67      1     0
## 137  2.33   1     0 7.00      1     0
## 138  5.00   1     1 6.67      1     1
## 139  2.67   1     0 6.67      1     1
## 140  4.33   0     1 7.00      1     0
## 141  6.00   0     0 7.00      1     1
## 142  5.33   1     1 7.00      1     1
## 143  5.67   0     1 6.67      1     1
## 144  5.00   0     0 6.67      1     0
## 145  5.33   1     0 6.67      1     1
## 146  3.67   0     1 6.67      1     0
## 147  4.00   1     0 6.67      1     0
## 148  2.33   1     0 6.67      1     0
## 149  5.00   0     0 6.00      1     0
## 150  5.33   1     1 7.00      0     0
## 151  5.67   0     0 6.00      1     0
## 152  4.33   1     0 6.33      1     1
## 153  4.67   0     0 6.67      1     0
## 154  4.00   0     1 6.33      1     0
## 155  2.67   1     1 7.00      0     1
## 156  5.00   1     1 7.00      1     0
## 157  2.67   0     0 6.33      1     0
## 158  6.33   1     0 7.00      0     0
## 159  6.00   1     0 7.00      1     1
## 160  2.67   0     1 7.00      1     0
## 161  2.67   0     0 7.00      1     0
## 162  5.33   0     1 7.00      1     1
## 163  2.67   0     0 6.33      1     0
## 164  6.00   0     0 6.33      1     0
## 165  2.67   1     1 6.00      1     0
## 166  6.33   0     0 7.00      1     0
## 167  4.67   0     0 6.33      1     0
## 168  5.33   0     1 7.00      1     0
## 169  5.67   1     0 6.67      1     0
## 170  5.33   1     1 6.67      1     0
## 171  4.67   0     0 6.33      1     0
## 172  2.33   0     1 6.00      1     0
## 173  3.33   0     0 7.00      1     0
## 174  4.33   1     0 7.00      1     0
## 175  4.67   1     1 6.00      1     0
## 176  5.00   0     0 7.00      0     1
## 177  5.67   1     0 7.00      0     0
## 178  2.33   0     0 6.67      1     0
## 179  3.00   0     0 6.67      0     0
## 180  4.33   1     1 7.00      1     0
## 181  2.33   0     1 6.67      1     0
## 182  2.67   0     0 7.00      1     0
## 183  3.67   0     0 6.67      1     0
## 184  4.33   1     1 7.00      0     0
## 185  2.33   0     0 6.67      0     0
## 186  6.00   1     1 7.00      1     1
## 187  2.67   0     1 7.00      1     1
## 188  3.67   1     0 6.67      1     0
## 189  4.33   1     1 6.00      1     0
## 190  2.33   0     1 7.00      1     1
## 191  5.67   1     1 7.00      1     1
## 192  4.33   0     1 7.00      1     0
## 193  5.00   1     1 5.67      1     0
## 194  5.00   1     1 7.00      1     0
## 195  3.67   1     0 5.67      1     0
## 196  4.33   0     0 7.00      1     0
## 197  5.00   1     0 7.00      1     0
## 198  6.00   1     1 6.33      1     0
## 199  4.33   0     0 6.67      1     0</code></pre>
</div>
</div>
<div id="model-implementation" class="section level2">
<h2>Model Implementation</h2>
<div id="data-preparation" class="section level3">
<h3>Data Preparation</h3>
<p>The dataset used for model training and testing was preprocessed to
select relevant features and split into training and testing sets. The
target variable, ‘Buy,’ was extracted from the original cleaned data.
Features were selected based on Recursive Feature Elimination (RFE)
analysis, optimising model performance. The data was then split into 80%
training and 20% testing sets using stratified sampling to ensure a
balanced representation of classes.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a><span class="co"># Set the seed for reproducibility</span></span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a><span class="co"># Extract the target variable &#39;Buy&#39; from the original cleaned_data</span></span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a>response <span class="ot">&lt;-</span> cleaned_data<span class="sc">$</span>Buy</span>
<span id="cb33-6"><a href="#cb33-6" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" tabindex="-1"></a><span class="co"># List the chosen features</span></span>
<span id="cb33-8"><a href="#cb33-8" tabindex="-1"></a>chosen_features <span class="ot">&lt;-</span> predictors[, results<span class="sc">$</span>optVariables]</span>
<span id="cb33-9"><a href="#cb33-9" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" tabindex="-1"></a><span class="co"># Add the target variable &#39;Buy&#39; to the chosen features</span></span>
<span id="cb33-11"><a href="#cb33-11" tabindex="-1"></a>chosen_features<span class="sc">$</span>Buy <span class="ot">&lt;-</span> response</span>
<span id="cb33-12"><a href="#cb33-12" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" tabindex="-1"></a><span class="co"># Split the data into training and testing sets based on the chosen features</span></span>
<span id="cb33-14"><a href="#cb33-14" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(chosen_features<span class="sc">$</span>Buy, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb33-15"><a href="#cb33-15" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> chosen_features[index, ]</span>
<span id="cb33-16"><a href="#cb33-16" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> chosen_features[<span class="sc">-</span>index, ]</span></code></pre></div>
</div>
<div id="model-training" class="section level3">
<h3>Model Training</h3>
<p>A Random Forest model was chosen for its ability to handle complex
relationships and non-linearities in the data. The model was trained
using the training dataset with 10-fold cross-validation to evaluate
performance robustness. The number of trees in the forest was set to 100
to achieve a balance between model complexity and computational
efficiency.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="co"># Combine chosen features with the response variable</span></span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a>final_data <span class="ot">&lt;-</span> <span class="fu">cbind</span>(chosen_features, <span class="at">Buy =</span> response)</span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a><span class="co"># Set up the training control for 10-fold cross-validation</span></span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a>train_control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>)</span>
<span id="cb34-6"><a href="#cb34-6" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" tabindex="-1"></a><span class="co"># Train the Random Forest model with 10-fold cross-validation</span></span>
<span id="cb34-8"><a href="#cb34-8" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb34-9"><a href="#cb34-9" tabindex="-1"></a>final_rf_model <span class="ot">&lt;-</span> <span class="fu">train</span>(Buy <span class="sc">~</span> ., <span class="at">data =</span> final_data, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">trControl =</span> train_control, <span class="at">ntree =</span> <span class="dv">100</span>)</span>
<span id="cb34-10"><a href="#cb34-10" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" tabindex="-1"></a><span class="co"># Print the model summary</span></span>
<span id="cb34-12"><a href="#cb34-12" tabindex="-1"></a><span class="fu">print</span>(final_rf_model)</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 199 samples
##   6 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 179, 179, 179, 179, 179, 179, ... 
## Resampling results across tuning parameters:
## 
##   mtry  RMSE       Rsquared   MAE      
##   2     0.4186865  0.3058715  0.3588222
##   4     0.4213413  0.3061469  0.3368888
##   6     0.4199767  0.3164772  0.3320332
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was mtry = 2.</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a><span class="co"># Get variable importance</span></span>
<span id="cb36-2"><a href="#cb36-2" tabindex="-1"></a><span class="co"># Get variable importance</span></span>
<span id="cb36-3"><a href="#cb36-3" tabindex="-1"></a>final_importance <span class="ot">&lt;-</span> <span class="fu">varImp</span>(final_rf_model)</span>
<span id="cb36-4"><a href="#cb36-4" tabindex="-1"></a><span class="fu">print</span>(final_importance)</span></code></pre></div>
<pre><code>## rf variable importance
## 
##        Overall
## Compt  100.000
## Inc     18.895
## Env     17.511
## Lresi    8.227
## Trust    1.938
## Gender   0.000</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" tabindex="-1"></a><span class="fu">plot</span>(final_importance)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p><strong>Feature Importance Analysis:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Compt (Perceived Self-Competence):</strong> The feature
“Compt,” representing the perceived self-competence in identifying
certified rice, emerges as the most important factor with a value close
to 100. This high importance indicates that individuals’ confidence in
recognizing certified rice significantly influences their purchasing
behavior.</p></li>
<li><p><strong>Inc (Income Class):</strong> Following competence, the
feature “Inc,” which denotes the self-reported income class of
participants, holds notable importance in predicting purchase behavior.
While its importance is lower than competence, income still contributes
significantly to the model’s predictions, highlighting its role in
shaping consumer choices.</p></li>
<li><p><strong>Env (Environmental Consequences):</strong> Environmental
factors, represented by the feature “Env,” exhibit moderate importance,
positioning between competence and income in terms of influence. This
suggests that individuals’ perceptions of the psychological consequences
of environmentally friendly behavior play a notable role in their
decision-making process regarding rice purchase.</p></li>
<li><p><strong>Lresi (Belief in Reduced Residues):</strong> The feature
“Lresi,” indicating the belief that certified rice has fewer residues
compared to conventional rice, demonstrates relatively lower importance
compared to competence, income, and environmental factors. While still
contributing to the model’s predictions, life satisfaction ranks lower
in terms of influence.</p></li>
<li><p><strong>Trust (Trust in Certification System):</strong> Trust in
the food quality certification system for rice, represented by the
feature “Trust,” holds a position of importance lower than belief in
reduced residues but higher than gender. Although trust contributes to
predicting purchase behavior, its impact is less significant compared to
other factors.</p></li>
<li><p><strong>Gender:</strong> Gender emerges as the feature with the
lowest importance among those analyzed. While still playing a role in
the model’s predictions, gender has no influence compared to competence,
income, environmental factors, trust, and belief in reduced
residues.</p></li>
</ol>
<p><strong>Conclusion:</strong> The analysis of feature importance
highlights the significant role of perceived self-competence, income
class, environmental perceptions and belief in reduced residues in
predicting purchase behavior of certified rice.</p>
</div>
<div id="model-evaluation" class="section level3">
<h3>Model Evaluation</h3>
<p>The trained Random Forest model was evaluated using various metrics
to assess its performance. Variable importance analysis was conducted to
identify the most influential features in predicting purchase behavior.
The model’s overall performance was assessed using metrics such as
accuracy, precision, recall, and F1-score.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a><span class="co"># Predict on the testing set</span></span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(final_rf_model, <span class="at">newdata =</span> test_data)</span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" tabindex="-1"></a><span class="co"># Define a threshold</span></span>
<span id="cb39-5"><a href="#cb39-5" tabindex="-1"></a>threshold <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb39-6"><a href="#cb39-6" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" tabindex="-1"></a><span class="co"># Convert predictions to binary values</span></span>
<span id="cb39-8"><a href="#cb39-8" tabindex="-1"></a>binary_predictions <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(predictions <span class="sc">&gt;=</span> threshold, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb39-9"><a href="#cb39-9" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" tabindex="-1"></a><span class="co"># Ensure that both predicted and actual values are factors</span></span>
<span id="cb39-11"><a href="#cb39-11" tabindex="-1"></a>binary_predictions <span class="ot">&lt;-</span> <span class="fu">factor</span>(binary_predictions)</span>
<span id="cb39-12"><a href="#cb39-12" tabindex="-1"></a>test_data<span class="sc">$</span>Buy <span class="ot">&lt;-</span> <span class="fu">factor</span>(test_data<span class="sc">$</span>Buy)</span>
<span id="cb39-13"><a href="#cb39-13" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" tabindex="-1"></a><span class="co"># Evaluate the model with the confusion matrix</span></span>
<span id="cb39-15"><a href="#cb39-15" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(binary_predictions, test_data<span class="sc">$</span>Buy)</span>
<span id="cb39-16"><a href="#cb39-16" tabindex="-1"></a></span>
<span id="cb39-17"><a href="#cb39-17" tabindex="-1"></a><span class="co"># Print confusion matrix</span></span>
<span id="cb39-18"><a href="#cb39-18" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Confusion Matrix:&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Confusion Matrix:&quot;</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a><span class="fu">print</span>(confusion_matrix)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  0  1
##          0 16  5
##          1  1 17
##                                           
##                Accuracy : 0.8462          
##                  95% CI : (0.6947, 0.9414)
##     No Information Rate : 0.5641          
##     P-Value [Acc &gt; NIR] : 0.0001782       
##                                           
##                   Kappa : 0.6953          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.2206714       
##                                           
##             Sensitivity : 0.9412          
##             Specificity : 0.7727          
##          Pos Pred Value : 0.7619          
##          Neg Pred Value : 0.9444          
##              Prevalence : 0.4359          
##          Detection Rate : 0.4103          
##    Detection Prevalence : 0.5385          
##       Balanced Accuracy : 0.8570          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a><span class="co"># Additional metrics</span></span>
<span id="cb43-2"><a href="#cb43-2" tabindex="-1"></a>accuracy <span class="ot">&lt;-</span> confusion_matrix<span class="sc">$</span>overall[<span class="st">&#39;Accuracy&#39;</span>]</span>
<span id="cb43-3"><a href="#cb43-3" tabindex="-1"></a>precision <span class="ot">&lt;-</span> confusion_matrix<span class="sc">$</span>byClass[<span class="st">&#39;Pos Pred Value&#39;</span>]</span>
<span id="cb43-4"><a href="#cb43-4" tabindex="-1"></a>recall <span class="ot">&lt;-</span> confusion_matrix<span class="sc">$</span>byClass[<span class="st">&#39;Sensitivity&#39;</span>]</span>
<span id="cb43-5"><a href="#cb43-5" tabindex="-1"></a>f1 <span class="ot">&lt;-</span> confusion_matrix<span class="sc">$</span>byClass[<span class="st">&#39;F1&#39;</span>]</span>
<span id="cb43-6"><a href="#cb43-6" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy:&quot;</span>, accuracy))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy: 0.846153846153846&quot;</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Precision:&quot;</span>, precision))</span></code></pre></div>
<pre><code>## [1] &quot;Precision: 0.761904761904762&quot;</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Recall:&quot;</span>, recall))</span></code></pre></div>
<pre><code>## [1] &quot;Recall: 0.941176470588235&quot;</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;F1-score:&quot;</span>, f1))</span></code></pre></div>
<pre><code>## [1] &quot;F1-score: 0.842105263157895&quot;</code></pre>
<p><strong>Confusion Matrix and Performance Metrics:</strong> The
confusion matrix provides a snapshot of the model’s performance in
predicting the purchase behavior of certified rice.</p>
<ul>
<li><strong>Accuracy:</strong> The model achieved an accuracy of 84.62%,
indicating the proportion of correctly classified instances out of the
total predictions.</li>
<li><strong>Precision:</strong> The precision, also known as the
positive predictive value, stands at 76.19%. This metric represents the
proportion of true positive predictions out of all positive predictions
made by the model.</li>
<li><strong>Recall (Sensitivity):</strong> The recall, or sensitivity,
measures the proportion of actual positive instances that were correctly
identified by the model. It is calculated at 94.12%.</li>
<li><strong>F1-score:</strong> The F1-score, a harmonic mean of
precision and recall, serves as a combined measure of the model’s
accuracy and completeness. The F1-score achieved by the model is
84.21%.</li>
</ul>
<p><strong>Analysis:</strong> The confusion matrix provides insights
into the model’s performance across different classes. It shows that out
of the 17 instances predicted as class 0 (not buying certified rice), 16
were correctly classified, resulting in a sensitivity of 94.12%. The
specificity, which measures the proportion of actual negative instances
correctly identified by the model, is 77.27%. This indicates that while
the model is quite effective at identifying positive instances, there is
still room for improving the identification of negative instances.</p>
<p><strong>Conclusion:</strong> The model demonstrates strong
performance in predicting the purchase behavior of certified rice, with
an accuracy of 84.62%. Despite its high sensitivity, the model could
benefit from improvements in specificity to enhance the identification
of instances where participants do not purchase certified rice. The
balanced accuracy of 85.70% underscores the model’s overall robustness,
though further refinements can be made to improve its precision and
specificity.</p>
</div>
<div id="roc-curve-analysis" class="section level3">
<h3>ROC Curve Analysis</h3>
<p>The ROC curve provided a visual representation of the model’s
performance in distinguishing between the positive and negative classes.
The plot depicted the True Positive Rate (Sensitivity) against the False
Positive Rate (1 - Specificity). A diagonal line represented a random
classifier, while the ROC curve illustrated the model’s discriminatory
power. The Area Under the Curve (AUC) quantified the model’s
performance, with a modereate AUC indicating fair predictive
accuracy.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a><span class="co"># Plot ROC curve with reversed x-axis</span></span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a>roc_curve <span class="ot">&lt;-</span> <span class="fu">roc</span>(test_data<span class="sc">$</span>Buy, <span class="fu">as.numeric</span>(predictions))</span></code></pre></div>
<pre><code>## Setting levels: control = 0, case = 1</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" tabindex="-1"></a><span class="fu">plot</span>(roc_curve, <span class="at">main=</span><span class="st">&quot;ROC Curve&quot;</span>, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">reverse=</span><span class="cn">TRUE</span>)</span>
<span id="cb54-2"><a href="#cb54-2" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" tabindex="-1"></a><span class="co"># Add diagonal line (random classifier)</span></span>
<span id="cb54-4"><a href="#cb54-4" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>, <span class="at">b=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb54-5"><a href="#cb54-5" tabindex="-1"></a></span>
<span id="cb54-6"><a href="#cb54-6" tabindex="-1"></a><span class="co"># Add legend</span></span>
<span id="cb54-7"><a href="#cb54-7" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;ROC Curve&quot;</span>, <span class="st">&quot;Random Classifier&quot;</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">lty=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">cex=</span><span class="fl">0.8</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" tabindex="-1"></a><span class="co"># Calculate AUC (Area Under the Curve)</span></span>
<span id="cb55-2"><a href="#cb55-2" tabindex="-1"></a>auc <span class="ot">&lt;-</span> <span class="fu">auc</span>(roc_curve)</span>
<span id="cb55-3"><a href="#cb55-3" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;AUC:&quot;</span>, auc))</span></code></pre></div>
<pre><code>## [1] &quot;AUC: 0.951871657754011&quot;</code></pre>
<p><strong>ROC Curve Results</strong></p>
<p><strong>Key Findings:</strong> The ROC curve analysis for the
classifier yielded an Area Under the Curve (AUC) of 0.9519. The AUC is a
measure of the classifier’s ability to distinguish between positive and
negative classes.</p>
<p><strong>Interpretation:</strong> An AUC of 0.9519 indicates that the
classifier possesses a strong discriminative power in distinguishing
between the positive and negative classes. This value suggests that the
classifier performs very well in terms of identifying true positive
instances while minimizing false positive instances.</p>
<p><strong>Implications:</strong> The high AUC value of 0.9519
demonstrates that the classifier is highly effective in differentiating
between the classes. This strong performance implies that the model is
well-calibrated and reliable for predicting the purchase behavior of
certified rice. While there is always room for fine-tuning, the current
model shows excellent discriminative ability, making it a robust tool
for this task.</p>
<p><strong>Conclusion:</strong> The AUC of 0.9519 suggests that the
classifier has a very high discriminative power. This indicates that the
model is highly effective and reliable in predicting the purchase
behavior of certified rice, showcasing the success of the current
model’s optimization and feature engineering efforts.</p>
</div>
</div>
<div id="shap-values-analysis-shap-shapley-additive-explanations"
class="section level2">
<h2>SHAP Values Analysis (SHAP (SHapley Additive exPlanations))</h2>
<p>SHAP values offered insights into the importance of features in
driving model predictions. By calculating the contribution of each
feature to the model’s output, SHAP values highlighted the factors
influencing purchase behavior. In our analysis, we utilized the Kernel
SHAP method to compute SHAP values for the Random Forest model. The SHAP
visualization (shapviz) provided a clear understanding of feature
importance through various plots, such as bee swarm plots, which
visualised the distribution of SHAP values for each feature. Insights
gained from SHAP analysis could inform marketing strategies and enhance
understanding of customer preferences.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" tabindex="-1"></a><span class="co"># Train the Random Forest model on the training set</span></span>
<span id="cb57-2"><a href="#cb57-2" tabindex="-1"></a>final_rf_model <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Buy <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">ntree =</span> <span class="dv">100</span>)</span>
<span id="cb57-3"><a href="#cb57-3" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" tabindex="-1"></a><span class="co"># Calculate Kernel SHAP values</span></span>
<span id="cb57-5"><a href="#cb57-5" tabindex="-1"></a><span class="fu">library</span>(kernelshap)</span>
<span id="cb57-6"><a href="#cb57-6" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">kernelshap</span>(final_rf_model, train_data[, <span class="sc">-</span><span class="fu">which</span>(<span class="fu">names</span>(train_data) <span class="sc">==</span> <span class="st">&quot;Buy&quot;</span>)], <span class="at">bg_X =</span> train_data)</span></code></pre></div>
<pre><code>## Exact Kernel SHAP values</code></pre>
<pre><code>##   |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |=================                                                     |  24%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  57%  |                                                                              |========================================                              |  58%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |==========================================                            |  61%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |=============================================                         |  64%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |===============================================                       |  68%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |=================================================                     |  71%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  79%  |                                                                              |========================================================              |  80%  |                                                                              |========================================================              |  81%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |=============================================================         |  88%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |===============================================================       |  91%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |====================================================================  |  98%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================|  99%  |                                                                              |======================================================================| 100%</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" tabindex="-1"></a><span class="co"># Convert to shapviz object</span></span>
<span id="cb60-2"><a href="#cb60-2" tabindex="-1"></a><span class="fu">library</span>(shapviz)</span>
<span id="cb60-3"><a href="#cb60-3" tabindex="-1"></a>sv <span class="ot">&lt;-</span> <span class="fu">shapviz</span>(s)</span>
<span id="cb60-4"><a href="#cb60-4" tabindex="-1"></a></span>
<span id="cb60-5"><a href="#cb60-5" tabindex="-1"></a><span class="co"># Gain insights</span></span>
<span id="cb60-6"><a href="#cb60-6" tabindex="-1"></a><span class="fu">sv_importance</span>(sv, <span class="at">kind =</span> <span class="st">&quot;bee&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p><strong>Purpose:</strong> Analysing the SHAP values helps us
understand how important different factors (features) are in predicting
rice purchase behavior.</p>
<p><strong>Findings:</strong></p>
<ul>
<li><strong>Competence:</strong> This seems to be the most important
factor, with high SHAP values suggesting people with strong competence
are more likely to be predicted as rice buyers.</li>
<li><strong>Income:</strong> Income also plays a role, but its effect
varies. Higher income levels might be associated with a higher chance of
buying rice, but the impact might not be the same across all income
brackets.</li>
<li><strong>Environment:</strong> The influence of environment on
predictions is moderate. This suggests that environmental factors might
have some impact, but it’s not as strong as competence or income.</li>
<li><strong>Lresi (Belief in Reduced Residues):</strong> The SHAP values
for life satisfaction are spread out evenly. This means it’s hard to say
definitively if being more or less satisfied with life influences rice
purchase behavior in a consistent way.</li>
<li><strong>Trust and Gender:</strong> Both these factors seem to have
mixed influences on predictions. Trust can have both positive and
negative effects, and the same might be true for gender.</li>
</ul>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>The primary objective of this analysis was to identify key factors
influencing the likelihood of buying certified rice using a Random
Forest model. Our findings highlight the significant roles of various
features, with Competence (perceived self-competence in identifying
certified rice) emerging as the most influential factor. Income,
Environment, <code>Lresi</code> (belief in reduced residues), and Trust
in the certification system also play notable roles.</p>
<p>The Random Forest model, validated through 10-fold cross-validation,
demonstrated high accuracy (84.62%) and a balanced accuracy score of
85.70%, indicating strong discriminative power. The ROC curve analysis,
with an AUC of 0.9519, further confirmed the model’s excellent
performance.</p>
<p>SHAP values provided deeper insights into feature importance,
revealing how individual attributes impacted model predictions. These
insights can guide targeted strategies to enhance the model’s predictive
accuracy and practical application.</p>
<p>This analysis demonstrates the importance of understanding feature
impacts in predictive modeling, offering a robust foundation for
predicting consumer behavior towards certified rice. The results
indicate that the current model is highly effective.</p>
<pre><code>
### Univariate Analysis of Numeric Variables

*Distribution of Numeric Variables*

``` r
# Define numeric variables
numeric_vars &lt;- c(&quot;Age&quot;, &quot;Hhsz&quot;)

# Select columns explicitly and gather data
data %&gt;%
  dplyr::select(all_of(numeric_vars)) %&gt;%
  tidyr::gather(key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;%
  ggplot(aes(x = value)) +
  geom_histogram(bins = 30, fill = &quot;blue&quot;, color = &quot;black&quot;, alpha = 0.7) +
  facet_wrap(~ variable, scales = &quot;free&quot;) +
  theme_minimal() +
  labs(title = &quot;Distribution of Numeric Variables&quot;)</code></pre>
<p><img src="random-forest_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>The distribution analysis of numerical variables in the rice dataset,
focusing on Age and Number of household members (Hhsz), reveals insights
into the shape, center, and spread of the data.</p>
<p><em>Shape of the Distribution:</em> The left histogram representing
Age appears to be unimodal and roughly symmetric. Most values cluster
around 50, with a spread between approximately 40 and 64. In contrast,
the right histogram depicting the Number of household members (Hhsz) is
also unimodal but exhibits a more pronounced peak around a specific
value, indicating a stronger central tendency.</p>
<p><em>Central Tendency:</em> The center of the data in the left
histogram, representing Age, is near 50, suggesting that the median or
mean age of participants is around this value. For the right histogram,
the peak indicates the central value (mean or median) around which most
data points are concentrated, providing insight into the typical size of
households among participants.</p>
<p><em>Variability:</em> The spread in the left histogram covering a
wider range (40 to 64) suggests greater variability in ages among
participants. Conversely, the right histogram displays less spread, with
values concentrated around a specific point, indicating less variability
in the number of household members among participants.</p>
<div id="univariate-analysis-of-categorical-variables-1"
class="section level3">
<h3>Univariate Analysis of Categorical Variables</h3>
<p><em>Distribution of Categorical Variables</em></p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" tabindex="-1"></a><span class="co"># Plot bar plots for categorical variables</span></span>
<span id="cb62-2"><a href="#cb62-2" tabindex="-1"></a>categorical_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Gender&quot;</span>, <span class="st">&quot;Inc&quot;</span>, <span class="st">&quot;Edu&quot;</span>, <span class="st">&quot;Child&quot;</span>, <span class="st">&quot;Buy&quot;</span>, <span class="st">&quot;Kno&quot;</span>, <span class="st">&quot;Compt&quot;</span>, <span class="st">&quot;Sens&quot;</span>, <span class="st">&quot;Health&quot;</span>, <span class="st">&quot;Conve&quot;</span>, <span class="st">&quot;Price&quot;</span>, <span class="st">&quot;Lresi&quot;</span>, <span class="st">&quot;Trust&quot;</span>, <span class="st">&quot;Env&quot;</span>, <span class="st">&quot;Read&quot;</span>, <span class="st">&quot;Cons&quot;</span>)</span>
<span id="cb62-3"><a href="#cb62-3" tabindex="-1"></a>data <span class="sc">%&gt;%</span> <span class="fu">select</span>(categorical_vars) <span class="sc">%&gt;%</span> </span>
<span id="cb62-4"><a href="#cb62-4" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> <span class="st">&quot;variable&quot;</span>, <span class="at">value =</span> <span class="st">&quot;value&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb62-5"><a href="#cb62-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> value, <span class="at">fill =</span> variable)) <span class="sc">+</span></span>
<span id="cb62-6"><a href="#cb62-6" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">position =</span> <span class="st">&quot;dodge&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb62-7"><a href="#cb62-7" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> variable, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span></span>
<span id="cb62-8"><a href="#cb62-8" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb62-9"><a href="#cb62-9" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Distribution of Categorical Variables&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-20-1.png" width="672" />
The distribution analysis of variables within the rice dataset reveals
notable trends and insights into participants’ behaviors and attitudes
towards certified rice consumption.</p>
<p>A significant portion of participants demonstrate regular purchasing
behavior of certified rice, as evidenced by peaks in the distribution
around 100 for those who purchased and lower values for those who did
not. This indicates a potential market for certified rice products.</p>
<p>The distribution of participants having children under 15 years of
age leans towards a higher proportion with children in this age group.
This demographic factor may influence buying habits or consumption
patterns, particularly regarding bulk purchases of rice.</p>
<p>Perceived competence in identifying certified rice tends to center
around the 4-5 range, suggesting moderate confidence levels among
participants. This highlights a potential opportunity for educational
interventions to enhance participant certainty in identifying certified
rice products.</p>
<p>Consumption patterns reveal that rice is considered an important
daily staple for many participants, with a peak around 150. This
underscores the significance of rice as a staple food within the diet of
a substantial group of participants.</p>
<p>Convenience beliefs regarding certified rice exhibit variation, with
some participants valuing convenience more highly than others. This
diversity suggests the importance of tailored marketing strategies that
address both preferences, emphasizing convenience benefits for some
while focusing on other aspects like health or environmental impact for
others.</p>
<p>The distribution of education levels within the dataset reflects
diversity, with the majority falling within high school, higher
education other than university, and university categories. This
underscores the importance of considering participants’ educational
backgrounds when designing communication or educational materials.</p>
<p>Awareness of environmental consequences associated with rice
production varies among participants, highlighting the need for targeted
interventions to raise awareness about the environmental impact of rice
production choices.</p>
<p>The gender distribution shows a predominantly female representation
within the dataset, indicating a gender imbalance among
participants.</p>
<p>Beliefs regarding the health benefits of certified rice exhibit
variation, with peaks around different values. This emphasizes the
importance of understanding diverse perceptions when promoting certified
rice, as some participants may prioritize health benefits more highly
than others.</p>
<p>Income class distribution indicates a balance between upper-class and
lower-income participants, suggesting a mix of income levels within the
dataset.</p>
<p>A higher proportion of participants demonstrate objective knowledge
of food quality certifications, indicating a level of familiarity and
awareness among the participants.</p>
<p>Trust in food quality certification systems varies among
participants, with some exhibiting high levels of trust while others
express lower confidence. Understanding these variations can inform
efforts to build trust and encourage participation in the certified rice
market.</p>
<p>These observations depict diverse perspectives and behaviors
regarding certified rice consumption.</p>
</div>
<div id="bivariate-analysis-numeric-vs-numeric-1"
class="section level3">
<h3>Bivariate Analysis (Numeric vs Numeric)</h3>
<p><em>Scatter plot of Age vs Household Size</em></p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" tabindex="-1"></a><span class="co"># Scatter plot between Age and Hhsz</span></span>
<span id="cb63-2"><a href="#cb63-2" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> Age, <span class="at">y =</span> Hhsz)) <span class="sc">+</span></span>
<span id="cb63-3"><a href="#cb63-3" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb63-4"><a href="#cb63-4" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb63-5"><a href="#cb63-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatter plot of Age vs Household Size&quot;</span>,</span>
<span id="cb63-6"><a href="#cb63-6" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Age&quot;</span>,</span>
<span id="cb63-7"><a href="#cb63-7" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Household Size&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-21-1.png" width="672" />
The scatter plot illustrates a notable trend indicating that as age
increases, there is a decrease in the number of household members. This
observation suggests a negative correlation between age and household
size. For instance, at an age of 70, there appears to be a reduced
number of household members compared to younger ages. This trend implies
that as individuals age, they may have fewer dependents or family
members living with them, which could be influenced by various factors
such as children leaving home, changes in family structure, or lifestyle
choices.</p>
</div>
<div id="bivariate-analysis-numeric-vs-categorical-1"
class="section level3">
<h3>Bivariate Analysis (Numeric vs Categorical)</h3>
<p><em>Age Distribution by Purchase Behaviour</em></p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" tabindex="-1"></a><span class="co"># Box plot of Age by Buy</span></span>
<span id="cb64-2"><a href="#cb64-2" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">as.factor</span>(Buy), <span class="at">y =</span> Age)) <span class="sc">+</span></span>
<span id="cb64-3"><a href="#cb64-3" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb64-4"><a href="#cb64-4" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb64-5"><a href="#cb64-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Box plot of Age by Purchase Behaviour&quot;</span>,</span>
<span id="cb64-6"><a href="#cb64-6" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Purchase Behavior (Buy)&quot;</span>,</span>
<span id="cb64-7"><a href="#cb64-7" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Age&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-22-1.png" width="672" />
The box plot shows the distribution of participant ages across two
groups: those who buy certified rice (<code>Buy</code> = 1) and those
who do not (<code>Buy</code> = 0).</p>
<p>While the median age is slightly lower for those who do not buy
certified rice, the overall distribution indicates that certified rice
is purchased by people across a variety of age groups. There is no
strong separation between the two groups, suggesting that age may not be
a defining factor when it comes to buying certified rice.</p>
</div>
<div id="bivariate-analysis-categorical-vs-categorical-1"
class="section level3">
<h3>Bivariate Analysis (Categorical vs Categorical)</h3>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" tabindex="-1"></a><span class="co"># Contingency table of Gender and Buy</span></span>
<span id="cb65-2"><a href="#cb65-2" tabindex="-1"></a><span class="fu">table</span>(data<span class="sc">$</span>Gender, data<span class="sc">$</span>Buy)</span></code></pre></div>
<pre><code>##    
##      0  1
##   0 15 12
##   1 80 92</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" tabindex="-1"></a><span class="co"># Bar plot of Gender by Buy</span></span>
<span id="cb67-2"><a href="#cb67-2" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">as.factor</span>(Gender), <span class="at">fill =</span> <span class="fu">as.factor</span>(Buy))) <span class="sc">+</span></span>
<span id="cb67-3"><a href="#cb67-3" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="sc">+</span></span>
<span id="cb67-4"><a href="#cb67-4" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb67-5"><a href="#cb67-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Bar plot of Gender by Purchase Behavior&quot;</span>,</span>
<span id="cb67-6"><a href="#cb67-6" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Gender&quot;</span>,</span>
<span id="cb67-7"><a href="#cb67-7" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;Purchase Behavior (Buy)&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-23-1.png" width="672" />
The bar plot indicates some associations between <code>Gender</code> and
<code>Buy</code> . For instance, a higher proportion of females
purchased certified rice compared to males.</p>
</div>
<div id="correlation-matrix-1" class="section level3">
<h3>Correlation Matrix</h3>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" tabindex="-1"></a><span class="co"># Compute correlation matrix for numeric variables</span></span>
<span id="cb68-2"><a href="#cb68-2" tabindex="-1"></a>numeric_data <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(Age, Hhsz)</span>
<span id="cb68-3"><a href="#cb68-3" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(numeric_data, <span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>)</span>
<span id="cb68-4"><a href="#cb68-4" tabindex="-1"></a></span>
<span id="cb68-5"><a href="#cb68-5" tabindex="-1"></a><span class="co"># Print the correlation matrix</span></span>
<span id="cb68-6"><a href="#cb68-6" tabindex="-1"></a><span class="fu">print</span>(cor_matrix)</span></code></pre></div>
<pre><code>##              Age        Hhsz
## Age   1.00000000 -0.04438532
## Hhsz -0.04438532  1.00000000</code></pre>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" tabindex="-1"></a><span class="co"># Visualize the correlation matrix</span></span>
<span id="cb70-2"><a href="#cb70-2" tabindex="-1"></a><span class="fu">ggcorrplot</span>(cor_matrix, <span class="at">method =</span> <span class="st">&quot;circle&quot;</span>, <span class="at">lab =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-24-1.png" width="672" />
The correlation analysis between the variables <code>Age</code> and
<code>Hhsz</code> reveals a weak negative relationship, indicating that
as age increases, there is a corresponding decrease in the number of
household members. This finding corroborates previous observations made
regarding the inverse association between age and household size.</p>
</div>
<div id="data-preprocessing-1" class="section level2">
<h2>Data Preprocessing</h2>
<div id="handling-missing-data-1" class="section level3">
<h3>Handling Missing Data</h3>
<p>Following an assessment of missing values within the dataset, it was
observed that the variables <code>Sens</code>, <code>Conve</code>,
<code>Health</code>, and <code>Price</code> contained missing values.
Specifically, <code>Health</code> exhibited two missing values, while
<code>Sens</code>, <code>Conve</code>, and <code>Price</code> each had
one missing value.</p>
<p>To address these missing values, a mode imputation strategy was
employed for the categorical variables (<code>Sens</code>,
<code>Conve</code>, <code>Health</code>, and <code>Price</code>). The
mode, representing the most frequently occurring value within each
respective variable, was calculated and used to replace the missing
values.</p>
<p>Following the imputation process, the imputed values were combined
with the original dataset. The old columns containing missing values
(<code>Sens</code>, <code>Conve</code>, <code>Health</code>, and
<code>Price</code>) were subsequently dropped from the combined dataset,
resulting in a cleaned dataset ready for analysis.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" tabindex="-1"></a><span class="co"># Define a function to calculate mode</span></span>
<span id="cb71-2"><a href="#cb71-2" tabindex="-1"></a>get_mode <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb71-3"><a href="#cb71-3" tabindex="-1"></a>  unique_x <span class="ot">&lt;-</span> <span class="fu">unique</span>(x)</span>
<span id="cb71-4"><a href="#cb71-4" tabindex="-1"></a>  unique_x[<span class="fu">which.max</span>(<span class="fu">tabulate</span>(<span class="fu">match</span>(x, unique_x)))]</span>
<span id="cb71-5"><a href="#cb71-5" tabindex="-1"></a>}</span>
<span id="cb71-6"><a href="#cb71-6" tabindex="-1"></a></span>
<span id="cb71-7"><a href="#cb71-7" tabindex="-1"></a><span class="co"># Imputation Strategy: Mode Imputation for categorical variables</span></span>
<span id="cb71-8"><a href="#cb71-8" tabindex="-1"></a>imputed_values <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span></span>
<span id="cb71-9"><a href="#cb71-9" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Sens =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(Sens), <span class="fu">get_mode</span>(data<span class="sc">$</span>Sens), Sens),</span>
<span id="cb71-10"><a href="#cb71-10" tabindex="-1"></a>         <span class="at">Conve =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(Conve), <span class="fu">get_mode</span>(data<span class="sc">$</span>Conve), Conve),</span>
<span id="cb71-11"><a href="#cb71-11" tabindex="-1"></a>         <span class="at">Health =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(Health), <span class="fu">get_mode</span>(data<span class="sc">$</span>Health), Health),</span>
<span id="cb71-12"><a href="#cb71-12" tabindex="-1"></a>         <span class="at">Price =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(Price), <span class="fu">get_mode</span>(data<span class="sc">$</span>Price), Price))</span>
<span id="cb71-13"><a href="#cb71-13" tabindex="-1"></a></span>
<span id="cb71-14"><a href="#cb71-14" tabindex="-1"></a><span class="co"># Combine imputed data with original dataset</span></span>
<span id="cb71-15"><a href="#cb71-15" tabindex="-1"></a>combined_data <span class="ot">&lt;-</span> <span class="fu">cbind</span>(data[, <span class="sc">!</span><span class="fu">names</span>(data) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Sens&quot;</span>, <span class="st">&quot;Conve&quot;</span>, <span class="st">&quot;Health&quot;</span>, <span class="st">&quot;Price&quot;</span>)],</span>
<span id="cb71-16"><a href="#cb71-16" tabindex="-1"></a>                        imputed_values[, <span class="fu">c</span>(<span class="st">&quot;Sens&quot;</span>, <span class="st">&quot;Conve&quot;</span>, <span class="st">&quot;Health&quot;</span>, <span class="st">&quot;Price&quot;</span>)])</span>
<span id="cb71-17"><a href="#cb71-17" tabindex="-1"></a></span>
<span id="cb71-18"><a href="#cb71-18" tabindex="-1"></a><span class="co"># Drop old columns with missing values</span></span>
<span id="cb71-19"><a href="#cb71-19" tabindex="-1"></a>cleaned_data <span class="ot">&lt;-</span> combined_data <span class="sc">%&gt;%</span></span>
<span id="cb71-20"><a href="#cb71-20" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">matches</span>(<span class="st">&quot;Sens|Conve|Health|Price&quot;</span>))</span>
<span id="cb71-21"><a href="#cb71-21" tabindex="-1"></a></span>
<span id="cb71-22"><a href="#cb71-22" tabindex="-1"></a><span class="co"># View the cleaned dataset</span></span>
<span id="cb71-23"><a href="#cb71-23" tabindex="-1"></a><span class="fu">head</span>(cleaned_data)</span></code></pre></div>
<pre><code>##   ID Age Gender Inc Edu Child Hhsz Buy Kno Compt Lresi Trust  Env Read Cons
## 1  1  34      1   0   5     1    4   1   1  5.00     1     0 6.33    1    1
## 2  2  41      1   0   2     1    3   1   0  4.67     1     0 7.00    1    1
## 3  3  49      1   1   5     1   10   1   0  5.33     0     0 6.00    1    1
## 4  4  47      1   0   2     1    4   1   0  4.67     1     0 6.67    1    1
## 5  5  59      1   0   4     1    3   1   1  4.67     0     0 6.00    1    1
## 6  6  34      1   0   4     1    3   0   1  3.33     0     0 7.00    1    1</code></pre>
</div>
<div id="age-categorisation-and-encoding-1" class="section level3">
<h3>Age Categorisation and Encoding</h3>
<p>The <code>Age</code> variable in the dataset was categorised into
four distinct age groups to facilitate analysis. These categories were
then encoded numerically for ease of use in statistical analysis and
machine learning models. The defined and encoded categories are as
follows:</p>
<p><em>Young Adults (25-34 years):</em> Encoded as 1. This group
represents younger participants who are at the early stages of their
adult life. <em>Middle-aged Adults (35-49 years):</em> Encoded as 2.
This category includes participants who are in the middle phase of their
adult life, often associated with peak career years and family
responsibilities. <em>Older Adults (50-64 years):</em> Encoded as 3.
Participants in this group are approaching retirement age and may have
different consumption patterns and health considerations. <em>Seniors
(65+ years):</em> Encoded as 4. This category includes participants who
are in the senior phase of their life, typically retired, with
potentially different purchasing behaviors and preferences.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" tabindex="-1"></a><span class="co"># Define age categories and encode them</span></span>
<span id="cb73-2"><a href="#cb73-2" tabindex="-1"></a>cleaned_data <span class="ot">&lt;-</span> cleaned_data <span class="sc">%&gt;%</span></span>
<span id="cb73-3"><a href="#cb73-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Age_Category =</span> <span class="fu">cut</span>(Age,</span>
<span id="cb73-4"><a href="#cb73-4" tabindex="-1"></a>                            <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">24</span>, <span class="dv">34</span>, <span class="dv">49</span>, <span class="dv">64</span>, <span class="cn">Inf</span>),</span>
<span id="cb73-5"><a href="#cb73-5" tabindex="-1"></a>                            <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Young Adults (25-34)&quot;</span>, <span class="st">&quot;Middle-aged Adults (35-49)&quot;</span>, <span class="st">&quot;Older Adults (50-64)&quot;</span>, <span class="st">&quot;Seniors (65+)&quot;</span>),</span>
<span id="cb73-6"><a href="#cb73-6" tabindex="-1"></a>                            <span class="at">right =</span> <span class="cn">FALSE</span>),</span>
<span id="cb73-7"><a href="#cb73-7" tabindex="-1"></a>         <span class="at">Age_Category_Encoded =</span> <span class="fu">as.integer</span>(<span class="fu">factor</span>(Age_Category, </span>
<span id="cb73-8"><a href="#cb73-8" tabindex="-1"></a>                                                  <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Young Adults (25-34)&quot;</span>, <span class="st">&quot;Middle-aged Adults (35-49)&quot;</span>, <span class="st">&quot;Older Adults (50-64)&quot;</span>, <span class="st">&quot;Seniors (65+)&quot;</span>))))</span>
<span id="cb73-9"><a href="#cb73-9" tabindex="-1"></a></span>
<span id="cb73-10"><a href="#cb73-10" tabindex="-1"></a><span class="co"># View the first few rows to check the new Age_Category_Encoded column</span></span>
<span id="cb73-11"><a href="#cb73-11" tabindex="-1"></a><span class="fu">head</span>(cleaned_data)</span></code></pre></div>
<pre><code>##   ID Age Gender Inc Edu Child Hhsz Buy Kno Compt Lresi Trust  Env Read Cons
## 1  1  34      1   0   5     1    4   1   1  5.00     1     0 6.33    1    1
## 2  2  41      1   0   2     1    3   1   0  4.67     1     0 7.00    1    1
## 3  3  49      1   1   5     1   10   1   0  5.33     0     0 6.00    1    1
## 4  4  47      1   0   2     1    4   1   0  4.67     1     0 6.67    1    1
## 5  5  59      1   0   4     1    3   1   1  4.67     0     0 6.00    1    1
## 6  6  34      1   0   4     1    3   0   1  3.33     0     0 7.00    1    1
##                 Age_Category Age_Category_Encoded
## 1 Middle-aged Adults (35-49)                    2
## 2 Middle-aged Adults (35-49)                    2
## 3       Older Adults (50-64)                    3
## 4 Middle-aged Adults (35-49)                    2
## 5       Older Adults (50-64)                    3
## 6 Middle-aged Adults (35-49)                    2</code></pre>
</div>
<div id="drop-unnecessary-columns-1" class="section level3">
<h3>Drop Unnecessary Columns</h3>
<p>In preparing the dataset for analysis, the <code>ID</code>,
<code>Age</code>, and <code>Age_Category</code> columns were removed.
This decision was made to streamline the dataset and focus on the
variables that are most pertinent to the analysis objectives. The ID
column, being a unique identifier for each participant, did not add
analytical value. The <code>Age</code> and <code>Age_Category</code>
columns were removed to avoid redundancy, given that the
<code>Age_Category_Encoded</code> column now effectively captures the
relevant age information in a numerical format suitable for
analysis.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" tabindex="-1"></a><span class="co"># Drop ID, Age, and Age_Category columns</span></span>
<span id="cb75-2"><a href="#cb75-2" tabindex="-1"></a>cleaned_data <span class="ot">&lt;-</span> cleaned_data <span class="sc">%&gt;%</span></span>
<span id="cb75-3"><a href="#cb75-3" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>ID, <span class="sc">-</span>Age, <span class="sc">-</span>Age_Category)</span>
<span id="cb75-4"><a href="#cb75-4" tabindex="-1"></a></span>
<span id="cb75-5"><a href="#cb75-5" tabindex="-1"></a><span class="co"># View the first few rows to check the updated dataset</span></span>
<span id="cb75-6"><a href="#cb75-6" tabindex="-1"></a><span class="fu">head</span>(cleaned_data)</span></code></pre></div>
<pre><code>##   Gender Inc Edu Child Hhsz Buy Kno Compt Lresi Trust  Env Read Cons
## 1      1   0   5     1    4   1   1  5.00     1     0 6.33    1    1
## 2      1   0   2     1    3   1   0  4.67     1     0 7.00    1    1
## 3      1   1   5     1   10   1   0  5.33     0     0 6.00    1    1
## 4      1   0   2     1    4   1   0  4.67     1     0 6.67    1    1
## 5      1   0   4     1    3   1   1  4.67     0     0 6.00    1    1
## 6      1   0   4     1    3   0   1  3.33     0     0 7.00    1    1
##   Age_Category_Encoded
## 1                    2
## 2                    2
## 3                    3
## 4                    2
## 5                    3
## 6                    2</code></pre>
</div>
<div id="feature-scaling-of-hhsz-1" class="section level3">
<h3>Feature Scaling of Hhsz</h3>
<p>Feature scaling was applied to the <code>Hhsz</code> (number of
household members) variable to standardise its values. This involved
transforming the variable to have a mean of 0 and a standard deviation
of 1. The standardised Hhsz variable, now represented as Hhsz_Scaled,
ensures that the feature is on a similar scale as other variables in the
dataset, which is crucial for many machine learning algorithms to
perform effectively.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" tabindex="-1"></a><span class="co"># Standardize the Hhsz variable</span></span>
<span id="cb77-2"><a href="#cb77-2" tabindex="-1"></a>cleaned_data <span class="ot">&lt;-</span> cleaned_data <span class="sc">%&gt;%</span></span>
<span id="cb77-3"><a href="#cb77-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Hhsz_Scaled =</span> <span class="fu">scale</span>(Hhsz)) <span class="sc">%&gt;%</span></span>
<span id="cb77-4"><a href="#cb77-4" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>Hhsz)  <span class="co"># Drop the original Hhsz column</span></span>
<span id="cb77-5"><a href="#cb77-5" tabindex="-1"></a></span>
<span id="cb77-6"><a href="#cb77-6" tabindex="-1"></a><span class="co"># View the first few rows to check the updated dataset</span></span>
<span id="cb77-7"><a href="#cb77-7" tabindex="-1"></a><span class="fu">head</span>(cleaned_data)</span></code></pre></div>
<pre><code>##   Gender Inc Edu Child Buy Kno Compt Lresi Trust  Env Read Cons
## 1      1   0   5     1   1   1  5.00     1     0 6.33    1    1
## 2      1   0   2     1   1   0  4.67     1     0 7.00    1    1
## 3      1   1   5     1   1   0  5.33     0     0 6.00    1    1
## 4      1   0   2     1   1   0  4.67     1     0 6.67    1    1
## 5      1   0   4     1   1   1  4.67     0     0 6.00    1    1
## 6      1   0   4     1   0   1  3.33     0     0 7.00    1    1
##   Age_Category_Encoded Hhsz_Scaled
## 1                    2  -0.2547872
## 2                    2  -0.8375763
## 3                    3   3.2419474
## 4                    2  -0.2547872
## 5                    3  -0.8375763
## 6                    2  -0.8375763</code></pre>
</div>
<div id="feature-selection-1" class="section level3">
<h3>Feature Selection</h3>
<p>Recursive Feature Elimination (RFE) was performed to identify the
most important features influencing the purchase behavior of certified
rice. Using cross-validation, the optimal subset of features was
selected to improve the model’s predictive performance. Please refer to
the output below.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" tabindex="-1"></a><span class="co"># Set up control for RFE</span></span>
<span id="cb79-2"><a href="#cb79-2" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">rfeControl</span>(<span class="at">functions=</span>rfFuncs, <span class="at">method=</span><span class="st">&quot;cv&quot;</span>, <span class="at">number=</span><span class="dv">10</span>)</span>
<span id="cb79-3"><a href="#cb79-3" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" tabindex="-1"></a><span class="co"># Define the predictor variables and the response variable</span></span>
<span id="cb79-5"><a href="#cb79-5" tabindex="-1"></a>predictors <span class="ot">&lt;-</span> cleaned_data[, <span class="sc">!</span><span class="fu">names</span>(cleaned_data) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Buy&quot;</span>)]</span>
<span id="cb79-6"><a href="#cb79-6" tabindex="-1"></a>response <span class="ot">&lt;-</span> cleaned_data<span class="sc">$</span>Buy</span>
<span id="cb79-7"><a href="#cb79-7" tabindex="-1"></a></span>
<span id="cb79-8"><a href="#cb79-8" tabindex="-1"></a><span class="co"># Perform RFE</span></span>
<span id="cb79-9"><a href="#cb79-9" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb79-10"><a href="#cb79-10" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">rfe</span>(predictors, response, <span class="at">sizes=</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(predictors)), <span class="at">rfeControl=</span>control)</span>
<span id="cb79-11"><a href="#cb79-11" tabindex="-1"></a></span>
<span id="cb79-12"><a href="#cb79-12" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb79-13"><a href="#cb79-13" tabindex="-1"></a><span class="fu">print</span>(results)</span></code></pre></div>
<pre><code>## 
## Recursive feature selection
## 
## Outer resampling method: Cross-Validated (10 fold) 
## 
## Resampling performance over subset size:
## 
##  Variables   RMSE Rsquared    MAE  RMSESD RsquaredSD   MAESD Selected
##          1 0.4420   0.2472 0.3701 0.05112    0.13388 0.03912         
##          2 0.4390   0.2442 0.3940 0.03993    0.12500 0.03501         
##          3 0.4342   0.2740 0.3988 0.04267    0.18356 0.03557         
##          4 0.4363   0.2774 0.4046 0.03742    0.17218 0.03095         
##          5 0.4358   0.2756 0.4060 0.03211    0.13965 0.03037         
##          6 0.4330   0.2679 0.3682 0.04593    0.11238 0.03586        *
##          7 0.4352   0.2574 0.3758 0.03742    0.10674 0.02923         
##          8 0.4360   0.2547 0.3814 0.03926    0.12287 0.03068         
##          9 0.4403   0.2430 0.3763 0.04379    0.12389 0.03293         
##         10 0.4378   0.2518 0.3785 0.04514    0.12242 0.03511         
##         11 0.4378   0.2470 0.3823 0.04085    0.10558 0.03213         
##         12 0.4412   0.2341 0.3822 0.03829    0.09765 0.02966         
##         13 0.4356   0.2527 0.3799 0.03932    0.10873 0.03162         
## 
## The top 5 variables (out of 6):
##    Compt, Inc, Lresi, Env, Gender</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" tabindex="-1"></a><span class="co"># List the chosen features</span></span>
<span id="cb81-2"><a href="#cb81-2" tabindex="-1"></a>chosen_features <span class="ot">&lt;-</span> predictors[, <span class="fu">predictors</span>(results)]</span>
<span id="cb81-3"><a href="#cb81-3" tabindex="-1"></a><span class="fu">print</span>(chosen_features)</span></code></pre></div>
<pre><code>##     Compt Inc Lresi  Env Gender Trust
## 1    5.00   0     1 6.33      1     0
## 2    4.67   0     1 7.00      1     0
## 3    5.33   1     0 6.00      1     0
## 4    4.67   0     1 6.67      1     0
## 5    4.67   0     0 6.00      1     0
## 6    3.33   0     0 7.00      1     0
## 7    6.33   1     0 6.67      1     1
## 8    5.67   0     1 6.00      1     0
## 9    4.00   1     1 7.00      1     0
## 10   4.67   1     1 6.33      0     0
## 11   5.00   1     0 6.00      1     0
## 12   6.00   1     0 6.00      1     1
## 13   6.00   1     0 7.00      1     0
## 14   3.67   1     0 7.00      0     0
## 15   3.00   0     0 7.00      1     0
## 16   4.33   0     0 6.00      1     0
## 17   6.00   0     0 7.00      1     0
## 18   4.33   0     0 6.00      1     0
## 19   6.67   1     0 6.67      1     0
## 20   5.67   1     1 6.33      1     0
## 21   5.33   0     0 7.00      1     0
## 22   2.33   1     0 6.67      1     0
## 23   4.67   1     0 7.00      1     0
## 24   3.00   1     1 7.00      1     0
## 25   2.67   0     0 6.67      1     0
## 26   4.00   0     1 6.67      1     0
## 27   2.33   1     1 5.67      1     0
## 28   4.33   0     1 6.33      1     1
## 29   4.67   1     0 7.00      1     0
## 30   2.67   1     0 6.33      0     0
## 31   6.33   1     1 6.00      0     1
## 32   2.67   1     0 7.00      1     1
## 33   3.67   1     1 6.00      0     0
## 34   4.33   0     1 7.00      1     0
## 35   1.67   0     1 6.67      1     0
## 36   6.00   1     1 7.00      1     1
## 37   7.00   1     1 6.00      1     1
## 38   5.00   0     1 7.00      1     0
## 39   5.67   0     0 6.67      0     0
## 40   5.33   0     1 6.67      0     0
## 41   4.67   1     1 7.00      0     1
## 42   2.33   1     0 6.00      1     0
## 43   2.67   1     0 7.00      1     1
## 44   3.33   0     0 7.00      1     0
## 45   2.33   0     0 7.00      1     0
## 46   6.00   0     1 6.67      1     0
## 47   4.33   1     1 6.00      1     1
## 48   5.00   0     1 6.00      1     0
## 49   2.33   0     0 6.67      1     0
## 50   5.67   1     1 7.00      1     0
## 51   5.00   0     0 7.00      0     0
## 52   4.33   1     1 6.67      1     0
## 53   5.67   0     1 6.67      1     0
## 54   5.67   1     1 7.00      1     1
## 55   3.67   0     0 7.00      1     1
## 56   4.00   0     0 6.33      1     0
## 57   6.33   1     1 7.00      1     0
## 58   6.00   1     1 6.67      1     1
## 59   6.00   0     1 6.33      1     0
## 60   5.00   1     0 6.67      1     0
## 61   4.33   0     0 6.00      1     0
## 62   1.33   0     0 7.00      1     0
## 63   5.33   1     1 7.00      1     1
## 64   7.00   1     1 7.00      1     0
## 65   5.00   1     0 5.67      1     0
## 66   6.00   0     0 6.67      1     0
## 67   5.00   1     1 6.00      1     1
## 68   1.67   0     0 6.67      1     0
## 69   2.67   1     0 6.00      1     1
## 70   3.67   0     0 7.00      1     0
## 71   4.67   0     1 6.67      1     0
## 72   5.67   1     1 6.00      1     0
## 73   2.33   0     1 7.00      0     1
## 74   5.67   0     1 6.33      0     0
## 75   5.67   0     1 7.00      1     1
## 76   2.00   0     1 7.00      1     0
## 77   3.00   0     1 6.00      1     0
## 78   5.00   1     0 6.67      1     0
## 79   7.00   1     1 6.00      1     0
## 80   3.67   0     1 6.33      1     1
## 81   4.67   1     0 6.00      1     0
## 82   2.00   0     0 6.67      1     0
## 83   6.33   1     0 6.67      1     0
## 84   6.00   0     0 5.33      1     0
## 85   2.67   0     0 6.67      0     1
## 86   6.00   1     0 7.00      0     0
## 87   5.33   1     1 7.00      1     1
## 88   4.67   0     0 6.00      1     0
## 89   5.33   1     1 7.00      1     1
## 90   6.00   0     1 7.00      0     0
## 91   1.67   1     0 5.67      0     0
## 92   6.33   0     1 6.33      1     1
## 93   5.00   0     0 7.00      1     0
## 94   7.00   0     1 7.00      1     0
## 95   5.00   1     1 6.67      1     0
## 96   4.00   0     1 7.00      1     0
## 97   3.33   0     0 5.67      1     0
## 98   2.33   1     0 7.00      1     0
## 99   3.67   0     0 6.00      1     0
## 100  6.33   1     1 6.33      1     1
## 101  2.67   0     0 6.67      1     0
## 102  4.00   1     1 6.67      0     0
## 103  3.00   1     0 6.33      1     0
## 104  4.67   0     0 7.00      1     0
## 105  5.67   1     0 7.00      1     1
## 106  6.00   0     1 6.67      1     0
## 107  4.33   0     1 6.67      1     0
## 108  4.67   0     0 7.00      1     0
## 109  3.33   1     1 6.67      1     1
## 110  4.33   1     0 6.67      1     1
## 111  4.00   1     1 6.00      1     0
## 112  4.67   1     0 7.00      1     0
## 113  4.00   1     1 7.00      1     0
## 114  2.67   1     0 6.33      1     0
## 115  6.67   1     1 7.00      1     0
## 116  3.67   0     0 6.67      1     1
## 117  3.00   1     0 6.67      1     0
## 118  2.67   0     0 6.67      1     1
## 119  2.00   0     0 7.00      0     0
## 120  4.33   1     0 7.00      0     0
## 121  5.33   1     1 6.67      1     0
## 122  5.00   0     0 6.33      1     0
## 123  4.33   0     1 7.00      1     1
## 124  2.33   0     0 6.67      0     0
## 125  2.33   0     1 7.00      1     0
## 126  5.33   0     1 7.00      1     0
## 127  2.33   0     0 6.67      1     0
## 128  5.00   0     0 6.00      1     0
## 129  4.67   1     0 7.00      1     1
## 130  5.00   1     0 7.00      1     1
## 131  4.33   0     1 6.33      1     0
## 132  3.33   0     0 6.33      1     0
## 133  7.00   1     1 7.00      1     1
## 134  2.67   1     0 6.67      1     0
## 135  5.33   0     0 7.00      1     0
## 136  3.00   0     0 6.67      1     0
## 137  2.33   1     0 7.00      1     0
## 138  5.00   1     1 6.67      1     1
## 139  2.67   1     0 6.67      1     1
## 140  4.33   0     1 7.00      1     0
## 141  6.00   0     0 7.00      1     1
## 142  5.33   1     1 7.00      1     1
## 143  5.67   0     1 6.67      1     1
## 144  5.00   0     0 6.67      1     0
## 145  5.33   1     0 6.67      1     1
## 146  3.67   0     1 6.67      1     0
## 147  4.00   1     0 6.67      1     0
## 148  2.33   1     0 6.67      1     0
## 149  5.00   0     0 6.00      1     0
## 150  5.33   1     1 7.00      0     0
## 151  5.67   0     0 6.00      1     0
## 152  4.33   1     0 6.33      1     1
## 153  4.67   0     0 6.67      1     0
## 154  4.00   0     1 6.33      1     0
## 155  2.67   1     1 7.00      0     1
## 156  5.00   1     1 7.00      1     0
## 157  2.67   0     0 6.33      1     0
## 158  6.33   1     0 7.00      0     0
## 159  6.00   1     0 7.00      1     1
## 160  2.67   0     1 7.00      1     0
## 161  2.67   0     0 7.00      1     0
## 162  5.33   0     1 7.00      1     1
## 163  2.67   0     0 6.33      1     0
## 164  6.00   0     0 6.33      1     0
## 165  2.67   1     1 6.00      1     0
## 166  6.33   0     0 7.00      1     0
## 167  4.67   0     0 6.33      1     0
## 168  5.33   0     1 7.00      1     0
## 169  5.67   1     0 6.67      1     0
## 170  5.33   1     1 6.67      1     0
## 171  4.67   0     0 6.33      1     0
## 172  2.33   0     1 6.00      1     0
## 173  3.33   0     0 7.00      1     0
## 174  4.33   1     0 7.00      1     0
## 175  4.67   1     1 6.00      1     0
## 176  5.00   0     0 7.00      0     1
## 177  5.67   1     0 7.00      0     0
## 178  2.33   0     0 6.67      1     0
## 179  3.00   0     0 6.67      0     0
## 180  4.33   1     1 7.00      1     0
## 181  2.33   0     1 6.67      1     0
## 182  2.67   0     0 7.00      1     0
## 183  3.67   0     0 6.67      1     0
## 184  4.33   1     1 7.00      0     0
## 185  2.33   0     0 6.67      0     0
## 186  6.00   1     1 7.00      1     1
## 187  2.67   0     1 7.00      1     1
## 188  3.67   1     0 6.67      1     0
## 189  4.33   1     1 6.00      1     0
## 190  2.33   0     1 7.00      1     1
## 191  5.67   1     1 7.00      1     1
## 192  4.33   0     1 7.00      1     0
## 193  5.00   1     1 5.67      1     0
## 194  5.00   1     1 7.00      1     0
## 195  3.67   1     0 5.67      1     0
## 196  4.33   0     0 7.00      1     0
## 197  5.00   1     0 7.00      1     0
## 198  6.00   1     1 6.33      1     0
## 199  4.33   0     0 6.67      1     0</code></pre>
</div>
</div>
<div id="model-implementation-1" class="section level2">
<h2>Model Implementation</h2>
<div id="data-preparation-1" class="section level3">
<h3>Data Preparation</h3>
<p>The dataset used for model training and testing was preprocessed to
select relevant features and split into training and testing sets. The
target variable, ‘Buy,’ was extracted from the original cleaned data.
Features were selected based on Recursive Feature Elimination (RFE)
analysis, optimising model performance. The data was then split into 80%
training and 20% testing sets using stratified sampling to ensure a
balanced representation of classes.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" tabindex="-1"></a><span class="co"># Set the seed for reproducibility</span></span>
<span id="cb83-2"><a href="#cb83-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb83-3"><a href="#cb83-3" tabindex="-1"></a></span>
<span id="cb83-4"><a href="#cb83-4" tabindex="-1"></a><span class="co"># Extract the target variable &#39;Buy&#39; from the original cleaned_data</span></span>
<span id="cb83-5"><a href="#cb83-5" tabindex="-1"></a>response <span class="ot">&lt;-</span> cleaned_data<span class="sc">$</span>Buy</span>
<span id="cb83-6"><a href="#cb83-6" tabindex="-1"></a></span>
<span id="cb83-7"><a href="#cb83-7" tabindex="-1"></a><span class="co"># List the chosen features</span></span>
<span id="cb83-8"><a href="#cb83-8" tabindex="-1"></a>chosen_features <span class="ot">&lt;-</span> predictors[, results<span class="sc">$</span>optVariables]</span>
<span id="cb83-9"><a href="#cb83-9" tabindex="-1"></a></span>
<span id="cb83-10"><a href="#cb83-10" tabindex="-1"></a><span class="co"># Add the target variable &#39;Buy&#39; to the chosen features</span></span>
<span id="cb83-11"><a href="#cb83-11" tabindex="-1"></a>chosen_features<span class="sc">$</span>Buy <span class="ot">&lt;-</span> response</span>
<span id="cb83-12"><a href="#cb83-12" tabindex="-1"></a></span>
<span id="cb83-13"><a href="#cb83-13" tabindex="-1"></a><span class="co"># Split the data into training and testing sets based on the chosen features</span></span>
<span id="cb83-14"><a href="#cb83-14" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(chosen_features<span class="sc">$</span>Buy, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb83-15"><a href="#cb83-15" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> chosen_features[index, ]</span>
<span id="cb83-16"><a href="#cb83-16" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> chosen_features[<span class="sc">-</span>index, ]</span></code></pre></div>
</div>
<div id="model-training-1" class="section level3">
<h3>Model Training</h3>
<p>A Random Forest model was chosen for its ability to handle complex
relationships and non-linearities in the data. The model was trained
using the training dataset with 10-fold cross-validation to evaluate
performance robustness. The number of trees in the forest was set to 100
to achieve a balance between model complexity and computational
efficiency.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" tabindex="-1"></a><span class="co"># Combine chosen features with the response variable</span></span>
<span id="cb84-2"><a href="#cb84-2" tabindex="-1"></a>final_data <span class="ot">&lt;-</span> <span class="fu">cbind</span>(chosen_features, <span class="at">Buy =</span> response)</span>
<span id="cb84-3"><a href="#cb84-3" tabindex="-1"></a></span>
<span id="cb84-4"><a href="#cb84-4" tabindex="-1"></a><span class="co"># Set up the training control for 10-fold cross-validation</span></span>
<span id="cb84-5"><a href="#cb84-5" tabindex="-1"></a>train_control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>)</span>
<span id="cb84-6"><a href="#cb84-6" tabindex="-1"></a></span>
<span id="cb84-7"><a href="#cb84-7" tabindex="-1"></a><span class="co"># Train the Random Forest model with 10-fold cross-validation</span></span>
<span id="cb84-8"><a href="#cb84-8" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb84-9"><a href="#cb84-9" tabindex="-1"></a>final_rf_model <span class="ot">&lt;-</span> <span class="fu">train</span>(Buy <span class="sc">~</span> ., <span class="at">data =</span> final_data, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">trControl =</span> train_control, <span class="at">ntree =</span> <span class="dv">100</span>)</span>
<span id="cb84-10"><a href="#cb84-10" tabindex="-1"></a></span>
<span id="cb84-11"><a href="#cb84-11" tabindex="-1"></a><span class="co"># Print the model summary</span></span>
<span id="cb84-12"><a href="#cb84-12" tabindex="-1"></a><span class="fu">print</span>(final_rf_model)</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 199 samples
##   6 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 179, 179, 179, 179, 179, 179, ... 
## Resampling results across tuning parameters:
## 
##   mtry  RMSE       Rsquared   MAE      
##   2     0.4186865  0.3058715  0.3588222
##   4     0.4213413  0.3061469  0.3368888
##   6     0.4199767  0.3164772  0.3320332
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was mtry = 2.</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" tabindex="-1"></a><span class="co"># Get variable importance</span></span>
<span id="cb86-2"><a href="#cb86-2" tabindex="-1"></a><span class="co"># Get variable importance</span></span>
<span id="cb86-3"><a href="#cb86-3" tabindex="-1"></a>final_importance <span class="ot">&lt;-</span> <span class="fu">varImp</span>(final_rf_model)</span>
<span id="cb86-4"><a href="#cb86-4" tabindex="-1"></a><span class="fu">print</span>(final_importance)</span></code></pre></div>
<pre><code>## rf variable importance
## 
##        Overall
## Compt  100.000
## Inc     18.895
## Env     17.511
## Lresi    8.227
## Trust    1.938
## Gender   0.000</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" tabindex="-1"></a><span class="fu">plot</span>(final_importance)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p><strong>Feature Importance Analysis:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Compt (Perceived Self-Competence):</strong> The feature
“Compt,” representing the perceived self-competence in identifying
certified rice, emerges as the most important factor with a value close
to 100. This high importance indicates that individuals’ confidence in
recognizing certified rice significantly influences their purchasing
behavior.</p></li>
<li><p><strong>Inc (Income Class):</strong> Following competence, the
feature “Inc,” which denotes the self-reported income class of
participants, holds notable importance in predicting purchase behavior.
While its importance is lower than competence, income still contributes
significantly to the model’s predictions, highlighting its role in
shaping consumer choices.</p></li>
<li><p><strong>Env (Environmental Consequences):</strong> Environmental
factors, represented by the feature “Env,” exhibit moderate importance,
positioning between competence and income in terms of influence. This
suggests that individuals’ perceptions of the psychological consequences
of environmentally friendly behavior play a notable role in their
decision-making process regarding rice purchase.</p></li>
<li><p><strong>Lresi (Belief in Reduced Residues):</strong> The feature
“Lresi,” indicating the belief that certified rice has fewer residues
compared to conventional rice, demonstrates relatively lower importance
compared to competence, income, and environmental factors. While still
contributing to the model’s predictions, life satisfaction ranks lower
in terms of influence.</p></li>
<li><p><strong>Trust (Trust in Certification System):</strong> Trust in
the food quality certification system for rice, represented by the
feature “Trust,” holds a position of importance lower than belief in
reduced residues but higher than gender. Although trust contributes to
predicting purchase behavior, its impact is less significant compared to
other factors.</p></li>
<li><p><strong>Gender:</strong> Gender emerges as the feature with the
lowest importance among those analyzed. While still playing a role in
the model’s predictions, gender has no influence compared to competence,
income, environmental factors, trust, and belief in reduced
residues.</p></li>
</ol>
<p><strong>Conclusion:</strong> The analysis of feature importance
highlights the significant role of perceived self-competence, income
class, environmental perceptions and belief in reduced residues in
predicting purchase behavior of certified rice.</p>
</div>
<div id="model-evaluation-1" class="section level3">
<h3>Model Evaluation</h3>
<p>The trained Random Forest model was evaluated using various metrics
to assess its performance. Variable importance analysis was conducted to
identify the most influential features in predicting purchase behavior.
The model’s overall performance was assessed using metrics such as
accuracy, precision, recall, and F1-score.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" tabindex="-1"></a><span class="co"># Predict on the testing set</span></span>
<span id="cb89-2"><a href="#cb89-2" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(final_rf_model, <span class="at">newdata =</span> test_data)</span>
<span id="cb89-3"><a href="#cb89-3" tabindex="-1"></a></span>
<span id="cb89-4"><a href="#cb89-4" tabindex="-1"></a><span class="co"># Define a threshold</span></span>
<span id="cb89-5"><a href="#cb89-5" tabindex="-1"></a>threshold <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb89-6"><a href="#cb89-6" tabindex="-1"></a></span>
<span id="cb89-7"><a href="#cb89-7" tabindex="-1"></a><span class="co"># Convert predictions to binary values</span></span>
<span id="cb89-8"><a href="#cb89-8" tabindex="-1"></a>binary_predictions <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(predictions <span class="sc">&gt;=</span> threshold, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb89-9"><a href="#cb89-9" tabindex="-1"></a></span>
<span id="cb89-10"><a href="#cb89-10" tabindex="-1"></a><span class="co"># Ensure that both predicted and actual values are factors</span></span>
<span id="cb89-11"><a href="#cb89-11" tabindex="-1"></a>binary_predictions <span class="ot">&lt;-</span> <span class="fu">factor</span>(binary_predictions)</span>
<span id="cb89-12"><a href="#cb89-12" tabindex="-1"></a>test_data<span class="sc">$</span>Buy <span class="ot">&lt;-</span> <span class="fu">factor</span>(test_data<span class="sc">$</span>Buy)</span>
<span id="cb89-13"><a href="#cb89-13" tabindex="-1"></a></span>
<span id="cb89-14"><a href="#cb89-14" tabindex="-1"></a><span class="co"># Evaluate the model with the confusion matrix</span></span>
<span id="cb89-15"><a href="#cb89-15" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(binary_predictions, test_data<span class="sc">$</span>Buy)</span>
<span id="cb89-16"><a href="#cb89-16" tabindex="-1"></a></span>
<span id="cb89-17"><a href="#cb89-17" tabindex="-1"></a><span class="co"># Print confusion matrix</span></span>
<span id="cb89-18"><a href="#cb89-18" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Confusion Matrix:&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Confusion Matrix:&quot;</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" tabindex="-1"></a><span class="fu">print</span>(confusion_matrix)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  0  1
##          0 16  5
##          1  1 17
##                                           
##                Accuracy : 0.8462          
##                  95% CI : (0.6947, 0.9414)
##     No Information Rate : 0.5641          
##     P-Value [Acc &gt; NIR] : 0.0001782       
##                                           
##                   Kappa : 0.6953          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.2206714       
##                                           
##             Sensitivity : 0.9412          
##             Specificity : 0.7727          
##          Pos Pred Value : 0.7619          
##          Neg Pred Value : 0.9444          
##              Prevalence : 0.4359          
##          Detection Rate : 0.4103          
##    Detection Prevalence : 0.5385          
##       Balanced Accuracy : 0.8570          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" tabindex="-1"></a><span class="co"># Additional metrics</span></span>
<span id="cb93-2"><a href="#cb93-2" tabindex="-1"></a>accuracy <span class="ot">&lt;-</span> confusion_matrix<span class="sc">$</span>overall[<span class="st">&#39;Accuracy&#39;</span>]</span>
<span id="cb93-3"><a href="#cb93-3" tabindex="-1"></a>precision <span class="ot">&lt;-</span> confusion_matrix<span class="sc">$</span>byClass[<span class="st">&#39;Pos Pred Value&#39;</span>]</span>
<span id="cb93-4"><a href="#cb93-4" tabindex="-1"></a>recall <span class="ot">&lt;-</span> confusion_matrix<span class="sc">$</span>byClass[<span class="st">&#39;Sensitivity&#39;</span>]</span>
<span id="cb93-5"><a href="#cb93-5" tabindex="-1"></a>f1 <span class="ot">&lt;-</span> confusion_matrix<span class="sc">$</span>byClass[<span class="st">&#39;F1&#39;</span>]</span>
<span id="cb93-6"><a href="#cb93-6" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy:&quot;</span>, accuracy))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy: 0.846153846153846&quot;</code></pre>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Precision:&quot;</span>, precision))</span></code></pre></div>
<pre><code>## [1] &quot;Precision: 0.761904761904762&quot;</code></pre>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Recall:&quot;</span>, recall))</span></code></pre></div>
<pre><code>## [1] &quot;Recall: 0.941176470588235&quot;</code></pre>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;F1-score:&quot;</span>, f1))</span></code></pre></div>
<pre><code>## [1] &quot;F1-score: 0.842105263157895&quot;</code></pre>
<p><strong>Confusion Matrix and Performance Metrics:</strong> The
confusion matrix provides a snapshot of the model’s performance in
predicting the purchase behavior of certified rice.</p>
<ul>
<li><strong>Accuracy:</strong> The model achieved an accuracy of 84.62%,
indicating the proportion of correctly classified instances out of the
total predictions.</li>
<li><strong>Precision:</strong> The precision, also known as the
positive predictive value, stands at 76.19%. This metric represents the
proportion of true positive predictions out of all positive predictions
made by the model.</li>
<li><strong>Recall (Sensitivity):</strong> The recall, or sensitivity,
measures the proportion of actual positive instances that were correctly
identified by the model. It is calculated at 94.12%.</li>
<li><strong>F1-score:</strong> The F1-score, a harmonic mean of
precision and recall, serves as a combined measure of the model’s
accuracy and completeness. The F1-score achieved by the model is
84.21%.</li>
</ul>
<p><strong>Analysis:</strong> The confusion matrix provides insights
into the model’s performance across different classes. It shows that out
of the 17 instances predicted as class 0 (not buying certified rice), 16
were correctly classified, resulting in a sensitivity of 94.12%. The
specificity, which measures the proportion of actual negative instances
correctly identified by the model, is 77.27%. This indicates that while
the model is quite effective at identifying positive instances, there is
still room for improving the identification of negative instances.</p>
<p><strong>Conclusion:</strong> The model demonstrates strong
performance in predicting the purchase behavior of certified rice, with
an accuracy of 84.62%. Despite its high sensitivity, the model could
benefit from improvements in specificity to enhance the identification
of instances where participants do not purchase certified rice. The
balanced accuracy of 85.70% underscores the model’s overall robustness,
though further refinements can be made to improve its precision and
specificity.</p>
</div>
<div id="roc-curve-analysis-1" class="section level3">
<h3>ROC Curve Analysis</h3>
<p>The ROC curve provided a visual representation of the model’s
performance in distinguishing between the positive and negative classes.
The plot depicted the True Positive Rate (Sensitivity) against the False
Positive Rate (1 - Specificity). A diagonal line represented a random
classifier, while the ROC curve illustrated the model’s discriminatory
power. The Area Under the Curve (AUC) quantified the model’s
performance, with a modereate AUC indicating fair predictive
accuracy.</p>
<div class="sourceCode" id="cb101"><pre
class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" tabindex="-1"></a><span class="co"># Plot ROC curve with reversed x-axis</span></span>
<span id="cb101-2"><a href="#cb101-2" tabindex="-1"></a>roc_curve <span class="ot">&lt;-</span> <span class="fu">roc</span>(test_data<span class="sc">$</span>Buy, <span class="fu">as.numeric</span>(predictions))</span></code></pre></div>
<pre><code>## Setting levels: control = 0, case = 1</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<div class="sourceCode" id="cb104"><pre
class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" tabindex="-1"></a><span class="fu">plot</span>(roc_curve, <span class="at">main=</span><span class="st">&quot;ROC Curve&quot;</span>, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">reverse=</span><span class="cn">TRUE</span>)</span>
<span id="cb104-2"><a href="#cb104-2" tabindex="-1"></a></span>
<span id="cb104-3"><a href="#cb104-3" tabindex="-1"></a><span class="co"># Add diagonal line (random classifier)</span></span>
<span id="cb104-4"><a href="#cb104-4" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>, <span class="at">b=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb104-5"><a href="#cb104-5" tabindex="-1"></a></span>
<span id="cb104-6"><a href="#cb104-6" tabindex="-1"></a><span class="co"># Add legend</span></span>
<span id="cb104-7"><a href="#cb104-7" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;ROC Curve&quot;</span>, <span class="st">&quot;Random Classifier&quot;</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">lty=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">cex=</span><span class="fl">0.8</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<div class="sourceCode" id="cb105"><pre
class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" tabindex="-1"></a><span class="co"># Calculate AUC (Area Under the Curve)</span></span>
<span id="cb105-2"><a href="#cb105-2" tabindex="-1"></a>auc <span class="ot">&lt;-</span> <span class="fu">auc</span>(roc_curve)</span>
<span id="cb105-3"><a href="#cb105-3" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;AUC:&quot;</span>, auc))</span></code></pre></div>
<pre><code>## [1] &quot;AUC: 0.951871657754011&quot;</code></pre>
<p><strong>ROC Curve Results</strong></p>
<p><strong>Key Findings:</strong> The ROC curve analysis for the
classifier yielded an Area Under the Curve (AUC) of 0.9519. The AUC is a
measure of the classifier’s ability to distinguish between positive and
negative classes.</p>
<p><strong>Interpretation:</strong> An AUC of 0.9519 indicates that the
classifier possesses a strong discriminative power in distinguishing
between the positive and negative classes. This value suggests that the
classifier performs very well in terms of identifying true positive
instances while minimizing false positive instances.</p>
<p><strong>Implications:</strong> The high AUC value of 0.9519
demonstrates that the classifier is highly effective in differentiating
between the classes. This strong performance implies that the model is
well-calibrated and reliable for predicting the purchase behavior of
certified rice. While there is always room for fine-tuning, the current
model shows excellent discriminative ability, making it a robust tool
for this task.</p>
<p><strong>Conclusion:</strong> The AUC of 0.9519 suggests that the
classifier has a very high discriminative power. This indicates that the
model is highly effective and reliable in predicting the purchase
behavior of certified rice, showcasing the success of the current
model’s optimization and feature engineering efforts.</p>
</div>
</div>
<div id="shap-values-analysis-shap-shapley-additive-explanations-1"
class="section level2">
<h2>SHAP Values Analysis (SHAP (SHapley Additive exPlanations))</h2>
<p>SHAP values offered insights into the importance of features in
driving model predictions. By calculating the contribution of each
feature to the model’s output, SHAP values highlighted the factors
influencing purchase behavior. In our analysis, we utilized the Kernel
SHAP method to compute SHAP values for the Random Forest model. The SHAP
visualization (shapviz) provided a clear understanding of feature
importance through various plots, such as bee swarm plots, which
visualised the distribution of SHAP values for each feature. Insights
gained from SHAP analysis could inform marketing strategies and enhance
understanding of customer preferences.</p>
<div class="sourceCode" id="cb107"><pre
class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" tabindex="-1"></a><span class="co"># Train the Random Forest model on the training set</span></span>
<span id="cb107-2"><a href="#cb107-2" tabindex="-1"></a>final_rf_model <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Buy <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">ntree =</span> <span class="dv">100</span>)</span>
<span id="cb107-3"><a href="#cb107-3" tabindex="-1"></a></span>
<span id="cb107-4"><a href="#cb107-4" tabindex="-1"></a><span class="co"># Calculate Kernel SHAP values</span></span>
<span id="cb107-5"><a href="#cb107-5" tabindex="-1"></a><span class="fu">library</span>(kernelshap)</span>
<span id="cb107-6"><a href="#cb107-6" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">kernelshap</span>(final_rf_model, train_data[, <span class="sc">-</span><span class="fu">which</span>(<span class="fu">names</span>(train_data) <span class="sc">==</span> <span class="st">&quot;Buy&quot;</span>)], <span class="at">bg_X =</span> train_data)</span></code></pre></div>
<pre><code>## Exact Kernel SHAP values</code></pre>
<pre><code>##   |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |=================                                                     |  24%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  57%  |                                                                              |========================================                              |  58%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |==========================================                            |  61%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |=============================================                         |  64%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |===============================================                       |  68%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |=================================================                     |  71%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  79%  |                                                                              |========================================================              |  80%  |                                                                              |========================================================              |  81%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |=============================================================         |  88%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |===============================================================       |  91%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |====================================================================  |  98%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================|  99%  |                                                                              |======================================================================| 100%</code></pre>
<div class="sourceCode" id="cb110"><pre
class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" tabindex="-1"></a><span class="co"># Convert to shapviz object</span></span>
<span id="cb110-2"><a href="#cb110-2" tabindex="-1"></a><span class="fu">library</span>(shapviz)</span>
<span id="cb110-3"><a href="#cb110-3" tabindex="-1"></a>sv <span class="ot">&lt;-</span> <span class="fu">shapviz</span>(s)</span>
<span id="cb110-4"><a href="#cb110-4" tabindex="-1"></a></span>
<span id="cb110-5"><a href="#cb110-5" tabindex="-1"></a><span class="co"># Gain insights</span></span>
<span id="cb110-6"><a href="#cb110-6" tabindex="-1"></a><span class="fu">sv_importance</span>(sv, <span class="at">kind =</span> <span class="st">&quot;bee&quot;</span>)</span></code></pre></div>
<p><img src="random-forest_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p><strong>Purpose:</strong> Analysing the SHAP values helps us
understand how important different factors (features) are in predicting
rice purchase behavior.</p>
<p><strong>Findings:</strong></p>
<ul>
<li><strong>Competence:</strong> This seems to be the most important
factor, with high SHAP values suggesting people with strong competence
are more likely to be predicted as rice buyers.</li>
<li><strong>Income:</strong> Income also plays a role, but its effect
varies. Higher income levels might be associated with a higher chance of
buying rice, but the impact might not be the same across all income
brackets.</li>
<li><strong>Environment:</strong> The influence of environment on
predictions is moderate. This suggests that environmental factors might
have some impact, but it’s not as strong as competence or income.</li>
<li><strong>Lresi (Belief in Reduced Residues):</strong> The SHAP values
for life satisfaction are spread out evenly. This means it’s hard to say
definitively if being more or less satisfied with life influences rice
purchase behavior in a consistent way.</li>
<li><strong>Trust and Gender:</strong> Both these factors seem to have
mixed influences on predictions. Trust can have both positive and
negative effects, and the same might be true for gender.</li>
</ul>
</div>
</div>
<div id="conclusion-1" class="section level1">
<h1>Conclusion</h1>
<p>The primary objective of this analysis was to identify key factors
influencing the likelihood of buying certified rice using a Random
Forest model. Our findings highlight the significant roles of various
features, with Competence (perceived self-competence in identifying
certified rice) emerging as the most influential factor. Income,
Environment, <code>Lresi</code> (belief in reduced residues), and Trust
in the certification system also play notable roles.</p>
<p>The Random Forest model, validated through 10-fold cross-validation,
demonstrated high accuracy (84.62%) and a balanced accuracy score of
85.70%, indicating strong discriminative power. The ROC curve analysis,
with an AUC of 0.9519, further confirmed the model’s excellent
performance.</p>
<p>SHAP values provided deeper insights into feature importance,
revealing how individual attributes impacted model predictions. These
insights can guide targeted strategies to enhance the model’s predictive
accuracy and practical application.</p>
<p>This analysis demonstrates the importance of understanding feature
impacts in predictive modeling, offering a robust foundation for
predicting consumer behavior towards certified rice. The results
indicate that the current model is highly effective.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
